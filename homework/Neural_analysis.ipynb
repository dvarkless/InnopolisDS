{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdLG1bU4x6t1JJjCr+1VMB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvarkless/InnopolisDS/blob/main/homework/Neural_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Анализ некоторых параметров Полносвязной и Сверточной нейронной сети"
      ],
      "metadata": {
        "id": "CF9ERJNJK2ZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# System and fundamental stuff\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "import functools\n",
        "import math\n",
        "import time\n",
        "from itertools import product\n",
        "\n",
        "# Types\n",
        "from typing import Callable\n",
        "from typing import OrderedDict as OrderedDictType\n",
        "from types import FunctionType\n",
        "\n",
        "# ML stuff\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchmetrics\n",
        "from torch.utils.data import DataLoader\n",
        "from torchmetrics import Accuracy, Precision, Recall\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose, Normalize, ToTensor\n",
        "\n",
        "# Other\n",
        "from alive_progress import alive_bar"
      ],
      "metadata": {
        "id": "WsUP3ejwLOSY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Надстройка для nn.Sequential"
      ],
      "metadata": {
        "id": "QRf201uNLpou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SeqModeler(nn.Sequential):\n",
        "    def __init__(self, ord_dict: OrderedDictType, device='cpu') -> None:\n",
        "        super().__init__(ord_dict)\n",
        "        self.device = torch.device(device)\n",
        "        self.to(self.device, non_blocking=True)\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = self.forward(X)\n",
        "        return torch.argmax(nn.Softmax(dim=1)(X), dim=1)\n"
      ],
      "metadata": {
        "id": "dV0x_H29LxcL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Тренер нейронных сетей"
      ],
      "metadata": {
        "id": "rni4ZvrXL332"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    __defaults = {\n",
        "        'batch_size': 100,\n",
        "        'device': 'cpu',\n",
        "        'epochs': 20,\n",
        "        'criterion': nn.CrossEntropyLoss(),\n",
        "        'enable_print': False,\n",
        "        'metrics': None,\n",
        "    }\n",
        "    __must_have_params = ['model_class', 'model_params', 'set_optimizer']\n",
        "\n",
        "    def __init__(self, **hp) -> None:\n",
        "        self.config = self.__defaults.copy()\n",
        "        for name, val in hp.items():\n",
        "            self.config[name] = val\n",
        "\n",
        "        for name in self.__must_have_params:\n",
        "            if name not in self.config:\n",
        "                print(f'Error: config parameter \"{name}\" is missing')\n",
        "                sys.exit(1)\n",
        "\n",
        "        self.model = self.config['model_class'](**self.config['model_params'])\n",
        "        opt_config = self.config['set_optimizer'].copy()\n",
        "        opt_config['params'] = self.model.parameters()\n",
        "        optimizer_name = opt_config.pop('name')\n",
        "        self.optimizer = getattr(torch.optim, optimizer_name)(**opt_config)\n",
        "        self.criterion = self.config['criterion']\n",
        "        self.device = torch.device(self.config['device'])\n",
        "\n",
        "    @property\n",
        "    def data_batch(self):\n",
        "        return self._data_batch\n",
        "\n",
        "    @data_batch.setter\n",
        "    def data_batch(self, data, /):\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            self._data_batch = data.to(self.device, non_blocking=True).float()\n",
        "        elif isinstance(data, np.ndarray):\n",
        "            self.data_batch = torch.Tensor(data)\n",
        "        else:\n",
        "            raise ValueError(f'data of type {type(data)} is unacceptable')\n",
        "\n",
        "    @property\n",
        "    def targets_batch(self):\n",
        "        return self._targets_batch\n",
        "\n",
        "    @targets_batch.setter\n",
        "    def targets_batch(self, targets):\n",
        "        if isinstance(targets, torch.Tensor):\n",
        "            self._targets_batch = targets.to(\n",
        "                self.device, non_blocking=True)\n",
        "        elif isinstance(targets, (np.ndarray, list, tuple)):\n",
        "            self.targets_batch = torch.Tensor(targets)\n",
        "        else:\n",
        "            raise ValueError(f'data of type {type(targets)} is unacceptable')\n",
        "\n",
        "    def fit(self, train_dataset, eval_dataset=None):\n",
        "        train_dl = DataLoader(train_dataset, self.config['batch_size'])\n",
        "        for epoch in range(self.config['epochs']):\n",
        "            avg_loss = []\n",
        "            for (inputs, targets) in train_dl:\n",
        "                self.data_batch, self.targets_batch = inputs, targets\n",
        "                self.optimizer.zero_grad()\n",
        "                yhat = self.model(self.data_batch)\n",
        "                loss = self.criterion(yhat, self.targets_batch)\n",
        "                avg_loss.append(loss)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "            avg_loss = torch.Tensor(avg_loss).mean()\n",
        "            avg_loss.to(self.device)\n",
        "            if self.config['enable_print']:\n",
        "                print(\n",
        "                    f'==========Epoch {epoch+1}/{self.config[\"epochs\"]}==========')\n",
        "                print(f'Loss: {avg_loss}')\n",
        "                if self.config['metrics'] and eval_dataset:\n",
        "                    metric_data = self.evaluate(eval_dataset)\n",
        "                    for metric, data in zip(self.config['metrics'], metric_data):\n",
        "                        print(f'{metric.__class__.__name__} = {data:.3f}')\n",
        "        return self\n",
        "\n",
        "    def evaluate(self, eval_dataset):\n",
        "        eval_dl = DataLoader(eval_dataset, batch_size=10000)\n",
        "        for data, targets in eval_dl:\n",
        "            self.data_batch, self.targets_batch = data, targets\n",
        "            predictions = self.model.predict(self.data_batch)\n",
        "            metric_data = []\n",
        "            for metric in self.config['metrics']:\n",
        "                metric_data.append(metric(predictions, self.targets_batch))\n",
        "            return tuple(metric_data)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)"
      ],
      "metadata": {
        "id": "u8RmCu7KL9Q1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Интерфейс для перебора параметров моделей"
      ],
      "metadata": {
        "id": "N7d3rytNMFO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def timer(attr):\n",
        "    \"\"\"\n",
        "        Декоратор используется для вывода времени,\n",
        "        за которое выполняется метод класса\n",
        "    \"\"\"\n",
        "    @functools.wraps(attr)\n",
        "    def _wrapper(self, *args, **kwargs):\n",
        "        start = time.perf_counter()\n",
        "        result = attr(self, *args, **kwargs)\n",
        "        runtime = time.perf_counter() - start\n",
        "        print(f'{runtime:.3f}s')\n",
        "        return result\n",
        "    return _wrapper\n",
        "\n",
        "\n",
        "class ModelRunner:\n",
        "    \"\"\"\n",
        "        Класс предназначенный для удобного запуска моделей машинного обучения.\n",
        "\n",
        "        Его возможности:\n",
        "            - Создание экземпляров моделей с задаваемыми через словарь параметрами\n",
        "              и их запуск через методы .fit() и .predict().\n",
        "            - Вывод шкалы прогресса и времени выполнения методов моделей\n",
        "            - Вывод различных метрик\n",
        "            - Запуск одной модели с комбинацией различных параметров\n",
        "\n",
        "        use case:\n",
        "            >>> defaults = {'lr': 0.01, 'epochs': 100}\n",
        "            >>> runner_inst = ModelRunner(ModelClass, timer=True, defaults=defaults, metrics=[accuracy])\n",
        "            >>> runner_inst.run(training_data, eval_input, eval_answers, params={'lr': [0.001, 0.005], 'batch_size':[100],})\n",
        "\n",
        "        inputs:\n",
        "            model_class - Class of your model (not instance), all parameters should be passed through **kwargs\n",
        "            defaults: dict - default kwargs for your model\n",
        "            metrics: list - list of functions, they must take only two positional args: foo(preds, answers)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_class, defaults=None, metrics=None, responsive_bar=False) -> None:\n",
        "        self.model_class = model_class\n",
        "        self.metrics = metrics\n",
        "        self._metric_data = []\n",
        "        self._parameters_data = []\n",
        "        if defaults is not None:\n",
        "            self.defaults = defaults\n",
        "\n",
        "        self._responsive_bar = responsive_bar\n",
        "\n",
        "    def run(self, train, eval, params: dict, one_vs_one: bool = False):\n",
        "        \"\"\"\n",
        "            Запустить проверку моделей с заданными данными и параметрами.\n",
        "\n",
        "            Итерируемые параметры задаются в словаре params в виде:\n",
        "                >>> params = {\n",
        "                >>>     'lr': [1,2,3,4]\n",
        "                >>>     'epochs': [100, 200]\n",
        "                >>>     }\n",
        "            Количество шагов проверки при этом зависит также от способа сочетания\n",
        "            параметров:\n",
        "                - При one_vs_one=True все доступные параметры сочетаются друг\n",
        "                с другом, в данном примере получается 8 шагов\n",
        "\n",
        "                - При one_vs_one=False параметры берутся по столбцам, при этом\n",
        "                если в каком то списке не хватает значений, то берется его последнее\n",
        "                значение в списке. В данном примере получается 4 шага\n",
        "\n",
        "            inputs:\n",
        "                train - training dataset, first column is answer labels\n",
        "                eval_input - evaluation dataset without answers\n",
        "                eval_answers - answer array in the same order as eval_input\n",
        "                               size = (1, N)\n",
        "                params - dict consisted of lists of the iterated parameters.\n",
        "                        every value must be a list, even singular vals\n",
        "                one_vs_one - parameters combination method, True is One vertus One;\n",
        "                            False is columswise combination.\n",
        "\n",
        "        \"\"\"\n",
        "        self._metric_data = []\n",
        "        self._models = []\n",
        "        curr_params = dict()\n",
        "        if one_vs_one:\n",
        "            # Проверка на наличие единственного значения в списке\n",
        "            if len(list(params.values())) <= 1:\n",
        "                pairs = list(*params.values())\n",
        "            else:\n",
        "                pairs = list(product(*list(params.values())))\n",
        "\n",
        "            if self._responsive_bar:\n",
        "                len_model_ticks = self.model_class(\n",
        "                    self.defaults).define_tick(None, additive=len(eval))\n",
        "            else:\n",
        "                len_model_ticks = 1\n",
        "            with alive_bar(len(list(pairs)*len_model_ticks), title=f'Проверка модели {self.model_class.__name__}', force_tty=True, bar='filling') as bar:\n",
        "                # Распаковка параметров\n",
        "                for vals in pairs:\n",
        "                    for i, key in enumerate(params.keys()):\n",
        "                        try:\n",
        "                            curr_params[key] = vals[i]\n",
        "                        except TypeError:\n",
        "                            curr_params[key] = vals\n",
        "\n",
        "                    print('-----With parameters-----')\n",
        "                    for key, val in curr_params.items():\n",
        "                        print(f'{key} = {val}')\n",
        "\n",
        "                    self._parameters_data.append(list(curr_params.values()))\n",
        "                    self._run_method(train, eval, curr_params, bar)\n",
        "                    bar()  # продвижение полосы прогресса\n",
        "        else:\n",
        "            iter_lens = [len(val) for val in params.values()]\n",
        "            if self._responsive_bar:\n",
        "                len_model_ticks = self.model_class(\n",
        "                    self.defaults).define_tick(None, additive=len(eval))\n",
        "            else:\n",
        "                len_model_ticks = 1\n",
        "            max_len = max(iter_lens)\n",
        "            with alive_bar(max_len*len_model_ticks, title=f'Проверка модели {self.model_class.__name__}', force_tty=True, bar='filling') as bar:\n",
        "                for i in range(max_len):\n",
        "                    for pos, key in enumerate(params.keys()):\n",
        "                        this_len = iter_lens[pos]\n",
        "                        try:\n",
        "                            curr_params[key] = params[key][min(\n",
        "                                this_len - 1, i)]\n",
        "                        except TypeError:\n",
        "                            curr_params[key] = params[key]\n",
        "\n",
        "                    print('-----With parameters-----')\n",
        "                    for key, val in curr_params.items():\n",
        "                        print(f'{key} = {val}')\n",
        "\n",
        "                    self._parameters_data.append(list(curr_params.values()))\n",
        "                    self._run_method(train, eval, curr_params, bar)\n",
        "                    bar()  # продвижение полосы прогресса\n",
        "\n",
        "        print(\"===============RESULTS=================\")\n",
        "        pos = self._highest_metric_pos(self._metric_data)\n",
        "        print(f'On iteration {pos}:')\n",
        "        print(f\"With hyperparameters: {self._parameters_data[pos]}\")\n",
        "        print(f'Got metrics: {self._metric_data[pos]}')\n",
        "\n",
        "    def _run_method(self, train, eval, params: dict, bar_obj: Callable):\n",
        "        \"\"\"\n",
        "            Внутренний обработчик ввода и вывода данных модели\n",
        "\n",
        "            inputs:\n",
        "                train - training dataset, first column is answer labels\n",
        "                eval_input - evaluation dataset without answers\n",
        "                eval_answers - answer array in the same order as eval_input\n",
        "                               size = (1, N)\n",
        "                params - dict of parameters that will be directly passed to the model\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        params_to_pass = self._mix_params(self.defaults, params)\n",
        "        self.model = self.model_class(**params_to_pass)\n",
        "    \n",
        "        self.device = self.model.device\n",
        "\n",
        "        eval_data, eval_targets = eval.data.to(self.device), eval.targets.to(self.device)\n",
        "        if self._responsive_bar:\n",
        "            self.model.define_tick(bar_obj, len(eval_targets))\n",
        "\n",
        "        print('~fit complete in ', end='')\n",
        "        self._run_train(train, eval)\n",
        "\n",
        "        print('~eval complete in ', end='')\n",
        "        answer = self._run_eval(eval_data)\n",
        "        self._comma_metrics(answer, eval_targets)\n",
        "        self._models.append(self.model)\n",
        "\n",
        "    def _mix_params(self, main, invasive):\n",
        "        \"\"\"\n",
        "            Внутренний метод для изменения словаря с параметрами\n",
        "\n",
        "            Вносит изменения в основной словарь с параметрами \n",
        "            из другого словаря. Основной словарь при этом не меняется.\n",
        "\n",
        "            inputs:\n",
        "                main: dict - dict to be  inserted values into\n",
        "                invasive: dict - mixed in values\n",
        "            output - new dict with mixed values\n",
        "        \"\"\"\n",
        "        maincpy = main.copy()\n",
        "        for key, val in invasive.items():\n",
        "            maincpy[key] = val\n",
        "        return maincpy\n",
        "\n",
        "    def _comma_metrics(self, preds, evals):\n",
        "        \"\"\"\n",
        "            Внутренний метод для получения метрик модели\n",
        "\n",
        "            Можно в последствии получить все метрики через\n",
        "            метод ModelRunner.get_metrics()\n",
        "\n",
        "            inputs:\n",
        "                preds: np.ndarray - model's predictions\n",
        "                evals: np.ndarray - true labels\n",
        "        \"\"\"\n",
        "        if not isinstance(evals, torch.Tensor):\n",
        "            evals = torch.Tensor(evals).to(self.device).int()\n",
        "        buff = []\n",
        "        for metric in self.metrics:\n",
        "            res = metric(preds, evals)\n",
        "            if isinstance(metric, FunctionType):\n",
        "                print(f\"    {metric.__name__} = {res:.3f}\")\n",
        "            else:\n",
        "                print(f\"    {metric.__class__.__name__} = {res:.3f}\")\n",
        "            buff.append(res)\n",
        "        self._metric_data.append(buff)\n",
        "\n",
        "    def _highest_metric_pos(self, metrics):\n",
        "        \"\"\"\n",
        "            Внутренний метод для получения позиции\n",
        "            наибольшего значения метрик.\n",
        "\n",
        "            Если видов метрик больше 1, то сравнивается их\n",
        "            среднее геометрическое.\n",
        "\n",
        "            inputs: \n",
        "                metrics: list - list of metrics, list of lists or\n",
        "                list of floats\n",
        "            output - index of the biggest value\n",
        "        \"\"\"\n",
        "        score = [math.prod(vals) for vals in metrics]\n",
        "        return score.index(max(score))\n",
        "\n",
        "    def get_models(self):\n",
        "        \"\"\"\n",
        "            Получить список со всеми использованными моделями\n",
        "\n",
        "            output - list of all calculated models\n",
        "        \"\"\"\n",
        "\n",
        "        return self._models\n",
        "\n",
        "    def get_metrics(self):\n",
        "        \"\"\"\n",
        "            Получить список со всеми значениями метрик\n",
        "\n",
        "            Если метрик больше одной, то выдается список\n",
        "            списков. Далее самим можно понять где какая метрика, \n",
        "            это не сложно\n",
        "\n",
        "            output - list of all calculated metrics\n",
        "        \"\"\"\n",
        "        return self._metric_data\n",
        "\n",
        "    def get_params(self):\n",
        "        \"\"\"\n",
        "            Получить список со всеми использованными\n",
        "            гиперпараметрами\n",
        "\n",
        "            Совпадает с тем, что передавалось в конструктор\n",
        "            класса и в метод ModelRunner.run()\n",
        "\n",
        "            output - list of hyperparameters\n",
        "        \"\"\"\n",
        "        return self._parameters_data\n",
        "\n",
        "    @timer\n",
        "    def _run_train(self, train, eval):\n",
        "        \"\"\"\n",
        "            Внутренний метод для запуска процесса \n",
        "            тренировки модели.\n",
        "\n",
        "            inputs:\n",
        "                train - training data\n",
        "            decorator prints the time it takes to run\n",
        "            this method\n",
        "        \"\"\"\n",
        "        self.model.fit(train, eval)\n",
        "\n",
        "    @timer\n",
        "    def _run_eval(self, eval_input):\n",
        "        \"\"\"\n",
        "            Внутренний метод для получения ответов модели.\n",
        "\n",
        "            inputs:\n",
        "                eval_input - data to process\n",
        "            output: np.ndarray - model's predictions\n",
        "\n",
        "            decorator prints the time it takes to run\n",
        "            this method\n",
        "        \"\"\"\n",
        "        self.model.data_batch = eval_input\n",
        "        return self.model.predict(self.model.data_batch)"
      ],
      "metadata": {
        "id": "d3-rv3hFMTMt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задаем начальные параметры\n",
        "Датасет - MNIST"
      ],
      "metadata": {
        "id": "m6NVOCYJOEnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    device = torch.device(\n",
        "        'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    trans = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
        "    train_dataset = MNIST('data/', train=True, download=True, transform=trans)\n",
        "    val_dataset = MNIST('data/', train=False, download=True, transform=trans)\n",
        "    model_params = OrderedDict([\n",
        "        ('batch1', nn.BatchNorm2d(1)),\n",
        "        ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "        ('batch2', nn.BatchNorm2d(16)),\n",
        "        ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "        ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "        ('flatten3', nn.Flatten()),\n",
        "        ('batch3', nn.BatchNorm1d(64*7*7)),\n",
        "        ('linear3', nn.Linear(64*7*7, 100)),\n",
        "        ('relu3', nn.ReLU()),\n",
        "        ('linear4', nn.Linear(100, 10)),\n",
        "        ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "\n",
        "    optim_params = {\n",
        "        'name': 'Adam',\n",
        "        'params': None,\n",
        "        'lr': 1e-3,\n",
        "    }\n",
        "    trainer_hp = {\n",
        "        'batch_size': 50,\n",
        "        'model_class': SeqModeler,\n",
        "        'model_params': {'ord_dict': model_params, 'device': device},\n",
        "        'set_optimizer': optim_params,\n",
        "        'device': device,\n",
        "        'criterion': nn.CrossEntropyLoss(),\n",
        "        'enable_print': False,\n",
        "        'metrics': [Accuracy(num_classes=10, average='macro').to(device), Recall(num_classes=10, average='macro').to(device), Precision(num_classes=10, average='macro').to(device)]\n",
        "    }"
      ],
      "metadata": {
        "id": "HAWladkuOLL-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Тестирование полносвязной сети\n",
        "##### Скорость обучения"
      ],
      "metadata": {
        "id": "-TNQO-W4OuQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 400)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('linear2', nn.Linear(400, 100)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "        ('linear3', nn.Linear(100, 10)),\n",
        "        ('relu3', nn.ReLU()),\n",
        "    ])\n",
        "optim_params_1 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-2,\n",
        "}\n",
        "optim_params_2 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-3,\n",
        "}\n",
        "\n",
        "optim_params_3 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-4,\n",
        "}\n",
        "\n",
        "optim_params_4 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-5,\n",
        "}\n",
        "\n",
        "trainer_hp['model_params']['ord_dict'] = model_params\n",
        "\n",
        "\n",
        "\n",
        "params = {\n",
        "    'set_optimizer': [optim_params_1, optim_params_2, optim_params_3, optim_params_4]\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "del model_runner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U3vCjuXsOzw1",
        "outputId": "e4004683-6f58-44e9-cb8d-27c4e0a52b6b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "on 0: -----With parameters-----\n",
            "on 0: set_optimizer = {'name': 'Adam', 'params': None, 'lr': 0.01}\n",
            "on 0: ~fit complete in 231.856s\n",
            "on 0: ~eval complete in 0.002s\n",
            "on 0:     Accuracy = 0.395\n",
            "on 0:     Recall = 0.395\n",
            "on 0:     Precision = 0.348\n",
            "on 1: -----With parameters-----\n",
            "on 1: set_optimizer = {'name': 'Adam', 'params': None, 'lr': 0.001}\n",
            "on 1: ~fit complete in 228.532s\n",
            "on 1: ~eval complete in 0.002s\n",
            "on 1:     Accuracy = 0.396\n",
            "on 1:     Recall = 0.396\n",
            "on 1:     Precision = 0.437\n",
            "on 2: -----With parameters-----\n",
            "on 2: set_optimizer = {'name': 'Adam', 'params': None, 'lr': 0.0001}\n",
            "on 2: ~fit complete in 228.466s\n",
            "on 2: ~eval complete in 0.003s\n",
            "on 2:     Accuracy = 0.395\n",
            "on 2:     Recall = 0.395\n",
            "on 2:     Precision = 0.434\n",
            "on 3: -----With parameters-----\n",
            "on 3: set_optimizer = {'name': 'Adam', 'params': None, 'lr': 1e-05}\n",
            "on 3: ~fit complete in\n",
            "Проверка модели Trainer |██████████████████████████████⚠︎         | (!) 3/4 [75%] in 13:12.5 (0.00/s)                    \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m model_runner \u001b[38;5;241m=\u001b[39m ModelRunner(Trainer, trainer_hp, metrics\u001b[38;5;241m=\u001b[39mtrainer_hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     37\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: [optim_params_1, optim_params_2, optim_params_3, optim_params_4]\n\u001b[1;32m     39\u001b[0m }\n\u001b[0;32m---> 41\u001b[0m \u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
            "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mModelRunner.run\u001b[0;34m(self, train, eval, params, one_vs_one)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    130\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameters_data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlist\u001b[39m(curr_params\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m--> 131\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m             bar()  \u001b[38;5;66;03m# продвижение полосы прогресса\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m===============RESULTS=================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mModelRunner._run_method\u001b[0;34m(self, train, eval, params, bar_obj)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdefine_tick(bar_obj, \u001b[38;5;28mlen\u001b[39m(eval_targets))\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~fit complete in \u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~eval complete in \u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    167\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eval(eval_data)\n",
            "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mtimer.<locals>._wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(attr)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      8\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m----> 9\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mattr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     runtime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mruntime\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mModelRunner._run_train\u001b[0;34m(self, train, eval)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;129m@timer\u001b[39m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train, \u001b[38;5;28meval\u001b[39m):\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m        Внутренний метод для запуска процесса \u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m        тренировки модели.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m        this method\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, train_dataset, eval_dataset)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     60\u001b[0m     avg_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m train_dl:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets_batch \u001b[38;5;241m=\u001b[39m inputs, targets\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/.venvs/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/.venvs/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/.venvs/jupyter/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/.venvs/jupyter/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/.venvs/jupyter/lib/python3.10/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
            "File \u001b[0;32m~/.venvs/jupyter/lib/python3.10/site-packages/torchvision/transforms/transforms.py:94\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 94\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "File \u001b[0;32m~/.venvs/jupyter/lib/python3.10/site-packages/torchvision/transforms/transforms.py:134\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Количество слоев"
      ],
      "metadata": {
        "id": "B3LJDZr9RZX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params_1 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 10)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "    ])\n",
        "params1 = {'ord_dict': model_params_1, 'device': device}\n",
        "model_params_2 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 200)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('linear2', nn.Linear(200, 10)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "    ])\n",
        "    \n",
        "params2 = {'ord_dict': model_params_2, 'device': device}\n",
        "model_params_3 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 400)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('linear2', nn.Linear(400, 100)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "        ('linear3', nn.Linear(100, 10)),\n",
        "        ('relu3', nn.ReLU()),\n",
        "    ])\n",
        "\n",
        "params3 = {'ord_dict': model_params_3, 'device': device}\n",
        "\n",
        "\n",
        "params = {\n",
        "    'model_params': [params1, params2, params3]\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "zjxBd9D1SnaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Количество нейронов в слоях"
      ],
      "metadata": {
        "id": "puhBNzmoTl_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params_1 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 100)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('linear2', nn.Linear(100, 20)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "        ('linear3', nn.Linear(20, 10)),\n",
        "        ('relu3', nn.ReLU()),\n",
        "    ]))\n",
        "params1 = {'ord_dict': model_params_1, 'device': device}\n",
        "model_params_2 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 400)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('linear2', nn.Linear(400, 100)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "        ('linear3', nn.Linear(100, 10)),\n",
        "        ('relu3', nn.ReLU()),\n",
        "    ])\n",
        "    \n",
        "params2 = {'ord_dict': model_params_2, 'device': device}\n",
        "model_params_3 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 600)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('linear2', nn.Linear(600, 300)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "        ('linear3', nn.Linear(300, 10)),\n",
        "        ('relu3', nn.ReLU()),\n",
        "    ])\n",
        "\n",
        "params3 = {'ord_dict': model_params_3, 'device': device}\n",
        "\n",
        "params = {\n",
        "    'model_params': [params1, params2, params3]\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "2PHTw5knTq9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Функции активации"
      ],
      "metadata": {
        "id": "18NuXsQuUWWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params_1 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 400)),\n",
        "        ('softplus1', nn.Softplus()),\n",
        "        ('linear2', nn.Linear(400, 100)),\n",
        "        ('softplus2', nn.Softplus(),\n",
        "        ('linear3', nn.Linear(100, 10)),\n",
        "        ('softplus3',nn.Softplus(), \n",
        "    ]))\n",
        "params1 = {'ord_dict': model_params_1, 'device': device}\n",
        "model_params_2 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 400)),\n",
        "        ('sigmoid1', nn.Sigmoid()),\n",
        "        ('linear2', nn.Linear(400, 100)),\n",
        "        ('sigmoid2', nn.Sigmoid()),\n",
        "        ('linear3', nn.Linear(100, 10)),\n",
        "        ('sigmoid3', nn.Sigmoid()),\n",
        "    ])\n",
        "    \n",
        "params2 = {'ord_dict': model_params_2, 'device': device}\n",
        "model_params_3 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 400)),\n",
        "        ('tanh1', nn.Tanh()),\n",
        "        ('linear2', nn.Linear(400, 100)),\n",
        "        ('tanh2', nn.Tanh()),\n",
        "        ('linear3', nn.Linear(100, 10)),\n",
        "        ('tanh3', nn.Tanh()),\n",
        "    ])\n",
        "\n",
        "params3 = {'ord_dict': model_params_3, 'device': device}\n",
        "\n",
        "params = {\n",
        "    'model_params': [params1, params2, params3]\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "LP1JxHUQUd9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сверточная нейронная сеть\n",
        "\n",
        "### Скорость обучения"
      ],
      "metadata": {
        "id": "Mst7FNWRXMbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*7*7, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "\n",
        "optim_params_1 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-2,\n",
        "}\n",
        "optim_params_2 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-3,\n",
        "}\n",
        "\n",
        "optim_params_3 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-4,\n",
        "}\n",
        "\n",
        "optim_params_4 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-5,\n",
        "}\n",
        "\n",
        "trainer_hp['model_params']['ord_dict'] = model_params\n",
        "\n",
        "\n",
        "params = {\n",
        "    'set_optimizer': [optim_params_1, optim_params_2, optim_params_3, optim_params_4]\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "-lzIKVMwXVS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Количество слоев"
      ],
      "metadata": {
        "id": "cuRqQuaYXwGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params_1 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(16*14*14, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "    \n",
        "params1 = {'ord_dict': model_params_1, 'device': device}\n",
        "\n",
        "model_params_2 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*7*7, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "params2 = {'ord_dict': model_params_2, 'device': device}\n",
        "    \n",
        "model_params_3 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 32, (2, 2), stride=1, padding=1)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv3', nn.Conv2d(32, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('maxpool3', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*3*3, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "params3 = {'ord_dict': model_params_3, 'device': device}\n",
        "\n",
        "params = {\n",
        "    'model_params': [params1, params2, params3],\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "gxI8vZEOX0bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Количество нейронов"
      ],
      "metadata": {
        "id": "MPpdCLzdZJ5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params_1 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 8, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(8, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(16*7*7, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "params1 = {'ord_dict': model_params_1, 'device': device}\n",
        "\n",
        "model_params_2 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*7*7, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "params2 = {'ord_dict': model_params_2, 'device': device}\n",
        "\n",
        "model_params_3 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(64, 128, (2, 2), stride=1, padding=1)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(128*7*7, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "params3 = {'ord_dict': model_params_3, 'device': device}\n",
        "\n",
        "params = {\n",
        "    'model_params': [params1, params2, params3],\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "QbCR1xpkZ7Br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Функции активации\n",
        "Вместо софтплюс возьму LeakyRELU"
      ],
      "metadata": {
        "id": "nwkQu3EKa2VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params_1 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.LeakyReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('relu2', nn.LeakyReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*7*7, 100)),\n",
        "    ('relu3', nn.LeakyReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.LeakyReLU()),\n",
        "    ])\n",
        "params1 = {'ord_dict': model_params_1, 'device': device}\n",
        "\n",
        "model_params_2 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('sigmoid1', nn.Sigmoid()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('sigmoid2', nn.Sigmoid()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*7*7, 100)),\n",
        "    ('sigmoid3', nn.Sigmoid()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('sigmoid4', nn.Sigmoid()),\n",
        "    ])\n",
        "params2 = {'ord_dict': model_params_2, 'device': device}\n",
        "\n",
        "model_params_3 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('tanh1', nn.Tanh()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('tanh2', nn.Tanh()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*7*7, 100)),\n",
        "    ('tanh3', nn.Tanh()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('tanh4', nn.tanh4()),\n",
        "    ])\n",
        "params3 = {'ord_dict': model_params_3, 'device': device}\n",
        "\n",
        "params = {\n",
        "    'model_params': [params1, params2, params3],\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "jeBgWGJabIsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Изменение фильтра"
      ],
      "metadata": {
        "id": "KgFQ5UlVcmUm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ajbdSX3Ycpis"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}