{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3s4SSge53rcg7rMtkUR4v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvarkless/InnopolisDS/blob/main/homeworks/Neural_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Анализ некоторых параметров Полносвязной и Сверточной нейронной сети"
      ],
      "metadata": {
        "id": "CF9ERJNJK2ZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# System and fundamental stuff\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "import functools\n",
        "import math\n",
        "import time\n",
        "from itertools import product\n",
        "\n",
        "# Types\n",
        "from typing import Callable\n",
        "from typing import OrderedDict as OrderedDictType\n",
        "from types import FunctionType\n",
        "\n",
        "# ML stuff\n",
        "import numpy as np\n",
        "from prettytable import PrettyTable\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchmetrics\n",
        "from torch.utils.data import DataLoader\n",
        "from torchmetrics import Accuracy, Precision, Recall\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose, Normalize, ToTensor\n",
        "\n",
        "# Other\n",
        "from alive_progress import alive_bar"
      ],
      "metadata": {
        "id": "WsUP3ejwLOSY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Надстройка для nn.Sequential"
      ],
      "metadata": {
        "id": "QRf201uNLpou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SeqModeler(nn.Sequential):\n",
        "    def __init__(self, ord_dict: OrderedDictType, device='cpu') -> None:\n",
        "        super().__init__(ord_dict)\n",
        "        self.device = torch.device(device)\n",
        "        self.to(self.device, non_blocking=True)\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = self.forward(X)\n",
        "        return torch.argmax(nn.Softmax(dim=1)(X), dim=1)\n"
      ],
      "metadata": {
        "id": "dV0x_H29LxcL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Тренер нейронных сетей"
      ],
      "metadata": {
        "id": "rni4ZvrXL332"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    __defaults = {\n",
        "        'batch_size': 100,\n",
        "        'device': 'cpu',\n",
        "        'epochs': 20,\n",
        "        'criterion': nn.CrossEntropyLoss(),\n",
        "        'enable_print': False,\n",
        "        'metrics': None,\n",
        "    }\n",
        "    __must_have_params = ['model_class', 'model_params', 'set_optimizer']\n",
        "\n",
        "    def __init__(self, **hp) -> None:\n",
        "        self.config = self.__defaults.copy()\n",
        "        for name, val in hp.items():\n",
        "            self.config[name] = val\n",
        "\n",
        "        for name in self.__must_have_params:\n",
        "            if name not in self.config:\n",
        "                print(f'Error: config parameter \"{name}\" is missing')\n",
        "                sys.exit(1)\n",
        "\n",
        "        self.model = self.config['model_class'](**self.config['model_params'])\n",
        "        opt_config = self.config['set_optimizer'].copy()\n",
        "        opt_config['params'] = self.model.parameters()\n",
        "        optimizer_name = opt_config.pop('name')\n",
        "        self.optimizer = getattr(torch.optim, optimizer_name)(**opt_config)\n",
        "        self.criterion = self.config['criterion']\n",
        "        self.device = torch.device(self.config['device'])\n",
        "\n",
        "    @property\n",
        "    def data_batch(self):\n",
        "        return self._data_batch\n",
        "\n",
        "    @data_batch.setter\n",
        "    def data_batch(self, data, /):\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            self._data_batch = data.to(self.device, non_blocking=True).float()\n",
        "        elif isinstance(data, np.ndarray):\n",
        "            self.data_batch = torch.Tensor(data)\n",
        "        else:\n",
        "            raise ValueError(f'data of type {type(data)} is unacceptable')\n",
        "\n",
        "    @property\n",
        "    def targets_batch(self):\n",
        "        return self._targets_batch\n",
        "\n",
        "    @targets_batch.setter\n",
        "    def targets_batch(self, targets):\n",
        "        if isinstance(targets, torch.Tensor):\n",
        "            self._targets_batch = targets.to(\n",
        "                self.device, non_blocking=True)\n",
        "        elif isinstance(targets, (np.ndarray, list, tuple)):\n",
        "            self.targets_batch = torch.Tensor(targets)\n",
        "        else:\n",
        "            raise ValueError(f'data of type {type(targets)} is unacceptable')\n",
        "\n",
        "    def fit(self, train_dataset, eval_dataset=None):\n",
        "        train_dl = DataLoader(train_dataset, self.config['batch_size'])\n",
        "        for epoch in range(self.config['epochs']):\n",
        "            avg_loss = []\n",
        "            for (inputs, targets) in train_dl:\n",
        "                self.data_batch, self.targets_batch = inputs, targets\n",
        "                self.optimizer.zero_grad()\n",
        "                yhat = self.model(self.data_batch)\n",
        "                loss = self.criterion(yhat, self.targets_batch)\n",
        "                avg_loss.append(loss)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "            avg_loss = torch.Tensor(avg_loss).mean()\n",
        "            avg_loss.to(self.device)\n",
        "            if self.config['enable_print']:\n",
        "                print(\n",
        "                    f'==========Epoch {epoch+1}/{self.config[\"epochs\"]}==========')\n",
        "                print(f'Loss: {avg_loss}')\n",
        "                if self.config['metrics'] and eval_dataset:\n",
        "                    metric_data = self.evaluate(eval_dataset)\n",
        "                    for metric, data in zip(self.config['metrics'], metric_data):\n",
        "                        print(f'{metric.__class__.__name__} = {data:.3f}')\n",
        "        return self\n",
        "\n",
        "    def evaluate(self, eval_dataset):\n",
        "        eval_dl = DataLoader(eval_dataset, batch_size=10000)\n",
        "        for data, targets in eval_dl:\n",
        "            self.data_batch, self.targets_batch = data, targets\n",
        "            predictions = self.model.predict(self.data_batch)\n",
        "            metric_data = []\n",
        "            for metric in self.config['metrics']:\n",
        "                metric_data.append(metric(predictions, self.targets_batch))\n",
        "            return tuple(metric_data)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)"
      ],
      "metadata": {
        "id": "u8RmCu7KL9Q1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Интерфейс для перебора параметров моделей"
      ],
      "metadata": {
        "id": "N7d3rytNMFO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def timer(attr):\n",
        "    \"\"\"\n",
        "        Декоратор используется для вывода времени,\n",
        "        за которое выполняется метод класса\n",
        "    \"\"\"\n",
        "    @functools.wraps(attr)\n",
        "    def _wrapper(self, *args, **kwargs):\n",
        "        start = time.perf_counter()\n",
        "        result = attr(self, *args, **kwargs)\n",
        "        runtime = time.perf_counter() - start\n",
        "        print(f'{runtime:.3f}s')\n",
        "        return result\n",
        "    return _wrapper\n",
        "\n",
        "\n",
        "class ModelRunner:\n",
        "    \"\"\"\n",
        "        Класс предназначенный для удобного запуска моделей машинного обучения.\n",
        "\n",
        "        Его возможности:\n",
        "            - Создание экземпляров моделей с задаваемыми через словарь параметрами\n",
        "              и их запуск через методы .fit() и .predict().\n",
        "            - Вывод шкалы прогресса и времени выполнения методов моделей\n",
        "            - Вывод различных метрик\n",
        "            - Запуск одной модели с комбинацией различных параметров\n",
        "\n",
        "        use case:\n",
        "            >>> defaults = {'lr': 0.01, 'epochs': 100}\n",
        "            >>> runner_inst = ModelRunner(ModelClass, timer=True, defaults=defaults, metrics=[accuracy])\n",
        "            >>> runner_inst.run(training_data, eval_input, eval_answers, params={'lr': [0.001, 0.005], 'batch_size':[100],})\n",
        "\n",
        "        inputs:\n",
        "            model_class - Class of your model (not instance), all parameters should be passed through **kwargs\n",
        "            defaults: dict - default kwargs for your model\n",
        "            metrics: list - list of functions, they must take only two positional args: foo(preds, answers)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_class, defaults=None, metrics=None, responsive_bar=False) -> None:\n",
        "        self.model_class = model_class\n",
        "        self.metrics = metrics\n",
        "        self._metric_data = []\n",
        "        self._parameters_data = []\n",
        "        if defaults is not None:\n",
        "            self.defaults = defaults\n",
        "\n",
        "        self._responsive_bar = responsive_bar\n",
        "\n",
        "    def run(self, train, eval, params: dict, one_vs_one: bool = False):\n",
        "        \"\"\"\n",
        "            Запустить проверку моделей с заданными данными и параметрами.\n",
        "\n",
        "            Итерируемые параметры задаются в словаре params в виде:\n",
        "                >>> params = {\n",
        "                >>>     'lr': [1,2,3,4]\n",
        "                >>>     'epochs': [100, 200]\n",
        "                >>>     }\n",
        "            Количество шагов проверки при этом зависит также от способа сочетания\n",
        "            параметров:\n",
        "                - При one_vs_one=True все доступные параметры сочетаются друг\n",
        "                с другом, в данном примере получается 8 шагов\n",
        "\n",
        "                - При one_vs_one=False параметры берутся по столбцам, при этом\n",
        "                если в каком то списке не хватает значений, то берется его последнее\n",
        "                значение в списке. В данном примере получается 4 шага\n",
        "\n",
        "            inputs:\n",
        "                train - training dataset, first column is answer labels\n",
        "                eval_input - evaluation dataset without answers\n",
        "                eval_answers - answer array in the same order as eval_input\n",
        "                               size = (1, N)\n",
        "                params - dict consisted of lists of the iterated parameters.\n",
        "                        every value must be a list, even singular vals\n",
        "                one_vs_one - parameters combination method, True is One vertus One;\n",
        "                            False is columswise combination.\n",
        "\n",
        "        \"\"\"\n",
        "        self._metric_data = []\n",
        "        self._models = []\n",
        "        curr_params = dict()\n",
        "        if one_vs_one:\n",
        "            # Проверка на наличие единственного значения в списке\n",
        "            if len(list(params.values())) <= 1:\n",
        "                pairs = list(*params.values())\n",
        "            else:\n",
        "                pairs = list(product(*list(params.values())))\n",
        "\n",
        "            if self._responsive_bar:\n",
        "                len_model_ticks = self.model_class(\n",
        "                    self.defaults).define_tick(None, additive=len(eval))\n",
        "            else:\n",
        "                len_model_ticks = 1\n",
        "            with alive_bar(len(list(pairs)*len_model_ticks), title=f'Проверка модели {self.model_class.__name__}', force_tty=True, bar='filling') as bar:\n",
        "                # Распаковка параметров\n",
        "                for vals in pairs:\n",
        "                    for i, key in enumerate(params.keys()):\n",
        "                        try:\n",
        "                            curr_params[key] = vals[i]\n",
        "                        except TypeError:\n",
        "                            curr_params[key] = vals\n",
        "\n",
        "                    print('-----With parameters-----')\n",
        "                    for key, val in curr_params.items():\n",
        "                        print(f'{key} = {val}')\n",
        "\n",
        "                    self._parameters_data.append(list(curr_params.values()))\n",
        "                    self._run_method(train, eval, curr_params, bar)\n",
        "                    bar()  # продвижение полосы прогресса\n",
        "        else:\n",
        "            iter_lens = [len(val) for val in params.values()]\n",
        "            if self._responsive_bar:\n",
        "                len_model_ticks = self.model_class(\n",
        "                    self.defaults).define_tick(None, additive=len(eval))\n",
        "            else:\n",
        "                len_model_ticks = 1\n",
        "            max_len = max(iter_lens)\n",
        "            with alive_bar(max_len*len_model_ticks, title=f'Проверка модели {self.model_class.__name__}', force_tty=True, bar='filling') as bar:\n",
        "                for i in range(max_len):\n",
        "                    for pos, key in enumerate(params.keys()):\n",
        "                        this_len = iter_lens[pos]\n",
        "                        try:\n",
        "                            curr_params[key] = params[key][min(\n",
        "                                this_len - 1, i)]\n",
        "                        except TypeError:\n",
        "                            curr_params[key] = params[key]\n",
        "\n",
        "                    print('-----With parameters-----')\n",
        "                    for key, val in curr_params.items():\n",
        "                        print(f'{key} = {val}')\n",
        "\n",
        "                    self._parameters_data.append(list(curr_params.values()))\n",
        "                    self._run_method(train, eval, curr_params, bar)\n",
        "                    bar()  # продвижение полосы прогресса\n",
        "\n",
        "        print(\"===============RESULTS=================\")\n",
        "        pos = self._highest_metric_pos(self._metric_data)\n",
        "        print(f'On iteration {pos}:')\n",
        "        print(f\"With hyperparameters: {self._parameters_data[pos]}\")\n",
        "        print(f'Got metrics: {self._metric_data[pos]}')\n",
        "\n",
        "    def _run_method(self, train, eval, params: dict, bar_obj: Callable):\n",
        "        \"\"\"\n",
        "            Внутренний обработчик ввода и вывода данных модели\n",
        "\n",
        "            inputs:\n",
        "                train - training dataset, first column is answer labels\n",
        "                eval_input - evaluation dataset without answers\n",
        "                eval_answers - answer array in the same order as eval_input\n",
        "                               size = (1, N)\n",
        "                params - dict of parameters that will be directly passed to the model\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        params_to_pass = self._mix_params(self.defaults, params)\n",
        "        self.model = self.model_class(**params_to_pass)\n",
        "    \n",
        "        self.device = self.model.device\n",
        "\n",
        "        if self._responsive_bar:\n",
        "            self.model.define_tick(bar_obj, len(eval))\n",
        "\n",
        "        print('~fit complete in ', end='')\n",
        "        self._run_train(train, eval)\n",
        "\n",
        "        print('~eval complete in ', end='')\n",
        "        targets, answer = self._run_eval(eval)\n",
        "        self._comma_metrics(answer, targets)\n",
        "        self._models.append(self.model)\n",
        "\n",
        "    def _mix_params(self, main, invasive):\n",
        "        \"\"\"\n",
        "            Внутренний метод для изменения словаря с параметрами\n",
        "\n",
        "            Вносит изменения в основной словарь с параметрами \n",
        "            из другого словаря. Основной словарь при этом не меняется.\n",
        "\n",
        "            inputs:\n",
        "                main: dict - dict to be  inserted values into\n",
        "                invasive: dict - mixed in values\n",
        "            output - new dict with mixed values\n",
        "        \"\"\"\n",
        "        maincpy = main.copy()\n",
        "        for key, val in invasive.items():\n",
        "            maincpy[key] = val\n",
        "        return maincpy\n",
        "\n",
        "    def _comma_metrics(self, preds, evals):\n",
        "        \"\"\"\n",
        "            Внутренний метод для получения метрик модели\n",
        "\n",
        "            Можно в последствии получить все метрики через\n",
        "            метод ModelRunner.get_metrics()\n",
        "\n",
        "            inputs:\n",
        "                preds: np.ndarray - model's predictions\n",
        "                evals: np.ndarray - true labels\n",
        "        \"\"\"\n",
        "        if not isinstance(evals, torch.Tensor):\n",
        "            evals = torch.Tensor(evals).to(self.device).int()\n",
        "        buff = []\n",
        "        for metric in self.metrics:\n",
        "            res = metric(preds, evals)\n",
        "            if isinstance(metric, FunctionType):\n",
        "                print(f\"    {metric.__name__} = {res:.3f}\")\n",
        "            else:\n",
        "                print(f\"    {metric.__class__.__name__} = {res:.3f}\")\n",
        "            buff.append(res)\n",
        "        self._metric_data.append(tuple(buff))\n",
        "\n",
        "    def _highest_metric_pos(self, metrics):\n",
        "        \"\"\"\n",
        "            Внутренний метод для получения позиции\n",
        "            наибольшего значения метрик.\n",
        "\n",
        "            Если видов метрик больше 1, то сравнивается их\n",
        "            среднее геометрическое.\n",
        "\n",
        "            inputs: \n",
        "                metrics: list - list of metrics, list of lists or\n",
        "                list of floats\n",
        "            output - index of the biggest value\n",
        "        \"\"\"\n",
        "        score = [math.prod(vals) for vals in metrics]\n",
        "        return score.index(max(score))\n",
        "\n",
        "    def get_models(self):\n",
        "        \"\"\"\n",
        "            Получить список со всеми использованными моделями\n",
        "\n",
        "            output - list of all calculated models\n",
        "        \"\"\"\n",
        "\n",
        "        return self._models\n",
        "\n",
        "    def get_metrics(self):\n",
        "        \"\"\"\n",
        "            Получить список со всеми значениями метрик\n",
        "\n",
        "            Если метрик больше одной, то выдается список\n",
        "            списков. Далее самим можно понять где какая метрика, \n",
        "            это не сложно\n",
        "\n",
        "            output - list of all calculated metrics\n",
        "        \"\"\"\n",
        "        return self._metric_data\n",
        "\n",
        "    def get_params(self):\n",
        "        \"\"\"\n",
        "            Получить список со всеми использованными\n",
        "            гиперпараметрами\n",
        "\n",
        "            Совпадает с тем, что передавалось в конструктор\n",
        "            класса и в метод ModelRunner.run()\n",
        "\n",
        "            output - list of hyperparameters\n",
        "        \"\"\"\n",
        "        return self._parameters_data\n",
        "\n",
        "    @timer\n",
        "    def _run_train(self, train, eval):\n",
        "        \"\"\"\n",
        "            Внутренний метод для запуска процесса \n",
        "            тренировки модели.\n",
        "\n",
        "            inputs:\n",
        "                train - training data\n",
        "        \"\"\"\n",
        "        self.model.fit(train, eval)\n",
        "\n",
        "    @timer\n",
        "    def _run_eval(self, eval_input) -> tuple:\n",
        "        \"\"\"\n",
        "            Внутренний метод для получения ответов модели.\n",
        "\n",
        "            inputs:\n",
        "                eval_input - data to process\n",
        "            output: tuple(torch.Tensor, torch.Tensor)\n",
        "                targets, predictions\n",
        "\n",
        "        \"\"\"\n",
        "        eval_dl = DataLoader(eval_input, batch_size=10000)\n",
        "        for eval_data, eval_targets in eval_dl:\n",
        "            self.model.data_batch, self.model.targets_batch = eval_data, eval_targets\n",
        "            eval_targets = self.model.targets_batch\n",
        "            break\n",
        "        else:\n",
        "            print('in ModelRunner._run_eval: eval is unbound')\n",
        "            sys.exit(1)\n",
        "        return eval_targets, self.model.predict(self.model.data_batch)\n",
        " "
      ],
      "metadata": {
        "id": "d3-rv3hFMTMt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задаем начальные параметры\n",
        "Датасет - MNIST"
      ],
      "metadata": {
        "id": "m6NVOCYJOEnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    device = torch.device(\n",
        "        'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    trans = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
        "    train_dataset = MNIST('data/', train=True, download=True, transform=trans)\n",
        "    val_dataset = MNIST('data/', train=False, download=True, transform=trans)\n",
        "    model_params = OrderedDict([\n",
        "        ('batch1', nn.BatchNorm2d(1)),\n",
        "        ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "        ('batch2', nn.BatchNorm2d(16)),\n",
        "        ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "        ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "        ('flatten3', nn.Flatten()),\n",
        "        ('batch3', nn.BatchNorm1d(64*7*7)),\n",
        "        ('linear3', nn.Linear(64*7*7, 100)),\n",
        "        ('relu3', nn.ReLU()),\n",
        "        ('linear4', nn.Linear(100, 10)),\n",
        "        ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "\n",
        "    optim_params = {\n",
        "        'name': 'Adam',\n",
        "        'params': None,\n",
        "        'lr': 1e-3,\n",
        "    }\n",
        "    trainer_hp = {\n",
        "        'batch_size': 50,\n",
        "        'model_class': SeqModeler,\n",
        "        'model_params': {'ord_dict': model_params, 'device': device},\n",
        "        'set_optimizer': optim_params,\n",
        "        'device': device,\n",
        "        'criterion': nn.CrossEntropyLoss(),\n",
        "        'enable_print': False,\n",
        "        'metrics': [Accuracy(num_classes=10, average='macro').to(device), Recall(num_classes=10, average='macro').to(device), Precision(num_classes=10, average='macro').to(device)]\n",
        "    }"
      ],
      "metadata": {
        "id": "HAWladkuOLL-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Тестирование полносвязной сети\n",
        "##### Скорость обучения"
      ],
      "metadata": {
        "id": "-TNQO-W4OuQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 400)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('linear2', nn.Linear(400, 100)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "        ('linear3', nn.Linear(100, 10)),\n",
        "        ('relu3', nn.ReLU()),\n",
        "    ])\n",
        "optim_params_1 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-2,\n",
        "}\n",
        "optim_params_2 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-3,\n",
        "}\n",
        "\n",
        "optim_params_3 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-4,\n",
        "}\n",
        "\n",
        "optim_params_4 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-5,\n",
        "}\n",
        "\n",
        "trainer_hp['model_params']['ord_dict'] = model_params\n",
        "\n",
        "\n",
        "\n",
        "params = {\n",
        "    'set_optimizer': [optim_params_1, optim_params_2, optim_params_3, optim_params_4]\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "metrics = model_runner.get_metrics()\n",
        "fc_lr_table = PrettyTable()\n",
        "\n",
        "fc_lr_table.add_column('Скорость обучения', ['1e-2', '1e-3', '1e-4', '1e-5'])\n",
        "fc_lr_table.add_column('Точность', list(map(lambda x: f'{float(x[0].detach().cpu().numpy()):.4f}', metrics)),)\n",
        "print(fc_lr_table)\n",
        "del model_runner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        },
        "id": "U3vCjuXsOzw1",
        "outputId": "376fa445-ff0a-4ade-ddc4-c0b811b280b0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "on 0: -----With parameters-----\n",
            "on 0: set_optimizer = {'name': 'Adam', 'params': None, 'lr': 0.01}\n",
            "on 0: ~fit complete in 242.974s\n",
            "on 0: ~eval complete in 1.597s\n",
            "on 0:     Accuracy = 0.765\n",
            "on 0:     Recall = 0.765\n",
            "on 0:     Precision = 0.697\n",
            "on 1: -----With parameters-----\n",
            "on 1: set_optimizer = {'name': 'Adam', 'params': None, 'lr': 0.001}\n",
            "on 1: ~fit complete in 238.658s\n",
            "on 1: ~eval complete in 1.615s\n",
            "on 1:     Accuracy = 0.775\n",
            "on 1:     Recall = 0.775\n",
            "on 1:     Precision = 0.705\n",
            "on 2: -----With parameters-----\n",
            "on 2: set_optimizer = {'name': 'Adam', 'params': None, 'lr': 0.0001}\n",
            "on 2: ~fit complete in 238.919s\n",
            "on 2: ~eval complete in 1.556s\n",
            "on 2:     Accuracy = 0.775\n",
            "on 2:     Recall = 0.775\n",
            "on 2:     Precision = 0.705\n",
            "on 3: -----With parameters-----\n",
            "on 3: set_optimizer = {'name': 'Adam', 'params': None, 'lr': 1e-05}\n",
            "on 3: ~fit complete in 239.677s\n",
            "on 3: ~eval complete in 1.505s\n",
            "on 3:     Accuracy = 0.775\n",
            "on 3:     Recall = 0.775\n",
            "on 3:     Precision = 0.705\n",
            "Проверка модели Trainer |████████████████████████████████████████| 4/4 [100%] in 16:06.6 (0.00/s)                       \n",
            "===============RESULTS=================\n",
            "On iteration 1:\n",
            "With hyperparameters: [{'name': 'Adam', 'params': None, 'lr': 0.001}]\n",
            "Got metrics: (tensor(0.7754, device='cuda:0'), tensor(0.7754, device='cuda:0'), tensor(0.7053, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m fc_lr_table \u001b[38;5;241m=\u001b[39m PrettyTable()\n\u001b[1;32m     46\u001b[0m fc_lr_table\u001b[38;5;241m.\u001b[39madd_column(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mТочность\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mfloat\u001b[39m(x[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:.4f\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics)),)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mfc_lr_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_column\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mСкорость обучения\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1e-2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1e-3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1e-4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(fc_lr_table)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model_runner\n",
            "File \u001b[0;32m~/.venvs/jupyter/lib/python3.10/site-packages/prettytable/prettytable.py:1457\u001b[0m, in \u001b[0;36mPrettyTable.add_column\u001b[0;34m(self, fieldname, column, align, valign)\u001b[0m\n\u001b[1;32m   1455\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rows[i]\u001b[38;5;241m.\u001b[39mappend(column[i])\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1458\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(column)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match number of rows \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1459\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rows)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1460\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Column length 3 does not match number of rows 4"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Количество слоев"
      ],
      "metadata": {
        "id": "B3LJDZr9RZX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params_1 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 10)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "    ])\n",
        "params1 = {'ord_dict': model_params_1, 'device': device}\n",
        "model_params_2 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 200)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('linear2', nn.Linear(200, 10)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "    ])\n",
        "    \n",
        "params2 = {'ord_dict': model_params_2, 'device': device}\n",
        "model_params_3 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 400)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('linear2', nn.Linear(400, 100)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "        ('linear3', nn.Linear(100, 10)),\n",
        "        ('relu3', nn.ReLU()),\n",
        "    ])\n",
        "\n",
        "params3 = {'ord_dict': model_params_3, 'device': device}\n",
        "\n",
        "\n",
        "params = {\n",
        "    'model_params': [params1, params2, params3]\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "metrics = model_runner.get_metrics()\n",
        "fc_layers_table = PrettyTable()\n",
        "\n",
        "fc_layers_table.add_column('Количество слоев', ['1', '2', '3'])\n",
        "fc_layers_table.add_column('Точность', list(map(lambda x: f'{float(x[0].detach().cpu().numpy()):.4f}', metrics)),)\n",
        "print(fc_layers_table)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "zjxBd9D1SnaJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da8d9e7d-1d10-4ead-c763-3eb79271c31f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "on 0: -----With parameters-----\n",
            "on 0: model_params = {'ord_dict': OrderedDict([('flatten1', Flatten(start_dim=1, end_dim=-1)), ('linear1', Linear(in_features=784, out_features=10, bias=True)), ('relu1', ReLU())]), 'device': device(type='cuda')}\n",
            "on 0: ~fit complete in 220.995s\n",
            "on 0: ~eval complete in 1.639s\n",
            "on 0:     Accuracy = 0.652\n",
            "on 0:     Recall = 0.652\n",
            "on 0:     Precision = 0.564\n",
            "on 1: -----With parameters-----\n",
            "on 1: model_params = {'ord_dict': OrderedDict([('flatten1', Flatten(start_dim=1, end_dim=-1)), ('linear1', Linear(in_features=784, out_features=200, bias=True)), ('relu1', ReLU()), ('linear2', Linear(in_features=200, out_features=10, bias=True)), ('relu2', ReLU())]), 'device': device(type='cuda')}\n",
            "on 1: ~fit complete in 228.271s\n",
            "on 1: ~eval complete in 1.580s\n",
            "on 1:     Accuracy = 0.787\n",
            "on 1:     Recall = 0.787\n",
            "on 1:     Precision = 0.717\n",
            "on 2: -----With parameters-----\n",
            "on 2: model_params = {'ord_dict': OrderedDict([('flatten1', Flatten(start_dim=1, end_dim=-1)), ('linear1', Linear(in_features=784, out_features=400, bias=True)), ('relu1', ReLU()), ('linear2', Linear(in_features=400, out_features=100, bias=True)), ('relu2', ReLU()), ('linear3', Linear(in_features=100, out_features=10, bias=True)), ('relu3', ReLU())]), 'device': device(type='cuda')}\n",
            "on 2: ~fit complete in 238.738s\n",
            "on 2: ~eval complete in 1.550s\n",
            "on 2:     Accuracy = 0.783\n",
            "on 2:     Recall = 0.783\n",
            "on 2:     Precision = 0.719\n",
            "Проверка модели Trainer |████████████████████████████████████████| 3/3 [100%] in 11:32.8 (0.00/s)                       \n",
            "===============RESULTS=================\n",
            "On iteration 1:\n",
            "With hyperparameters: [{'ord_dict': OrderedDict([('flatten1', Flatten(start_dim=1, end_dim=-1)), ('linear1', Linear(in_features=784, out_features=200, bias=True)), ('relu1', ReLU()), ('linear2', Linear(in_features=200, out_features=10, bias=True)), ('relu2', ReLU())]), 'device': device(type='cuda')}]\n",
            "Got metrics: (tensor(0.7870, device='cuda:0'), tensor(0.7870, device='cuda:0'), tensor(0.7169, device='cuda:0'))\n",
            "+----------+------------------+\n",
            "| Точность | Количество слоев |\n",
            "+----------+------------------+\n",
            "|  0.6523  |        1         |\n",
            "|  0.7870  |        2         |\n",
            "|  0.7828  |        3         |\n",
            "+----------+------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Количество нейронов в слоях"
      ],
      "metadata": {
        "id": "puhBNzmoTl_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params_1 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 100)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('linear2', nn.Linear(100, 20)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "        ('linear3', nn.Linear(20, 10)),\n",
        "        ('relu3', nn.ReLU()),\n",
        "    ]))\n",
        "params1 = {'ord_dict': model_params_1, 'device': device}\n",
        "model_params_2 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 400)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('linear2', nn.Linear(400, 100)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "        ('linear3', nn.Linear(100, 10)),\n",
        "        ('relu3', nn.ReLU()),\n",
        "    ])\n",
        "    \n",
        "params2 = {'ord_dict': model_params_2, 'device': device}\n",
        "model_params_3 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 600)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('linear2', nn.Linear(600, 300)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "        ('linear3', nn.Linear(300, 10)),\n",
        "        ('relu3', nn.ReLU()),\n",
        "    ])\n",
        "\n",
        "params3 = {'ord_dict': model_params_3, 'device': device}\n",
        "\n",
        "params = {\n",
        "    'model_params': [params1, params2, params3]\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "metrics = model_runner.get_metrics()\n",
        "fc_neurons_table = PrettyTable()\n",
        "fc_neurons_table.add_column('Количество нейронов', ['100 20', '400 100', '600 300'])\n",
        "fc_neurons_table.add_column('Точность', list(map(lambda x: f'{float(x[0].detach().cpu().numpy()):.4f}', metrics)),)\n",
        "print(fc_neurons_table)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "2PHTw5knTq9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Функции активации"
      ],
      "metadata": {
        "id": "18NuXsQuUWWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params_1 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 400)),\n",
        "        ('softplus1', nn.Softplus()),\n",
        "        ('linear2', nn.Linear(400, 100)),\n",
        "        ('softplus2', nn.Softplus(),\n",
        "        ('linear3', nn.Linear(100, 10)),\n",
        "        ('softplus3',nn.Softplus(), \n",
        "    ]))\n",
        "params1 = {'ord_dict': model_params_1, 'device': device}\n",
        "model_params_2 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 400)),\n",
        "        ('sigmoid1', nn.Sigmoid()),\n",
        "        ('linear2', nn.Linear(400, 100)),\n",
        "        ('sigmoid2', nn.Sigmoid()),\n",
        "        ('linear3', nn.Linear(100, 10)),\n",
        "        ('sigmoid3', nn.Sigmoid()),\n",
        "    ])\n",
        "    \n",
        "params2 = {'ord_dict': model_params_2, 'device': device}\n",
        "model_params_3 = OrderedDict([\n",
        "        ('flatten1',nn.Flatten()),\n",
        "        ('linear1', nn.Linear(784, 400)),\n",
        "        ('tanh1', nn.Tanh()),\n",
        "        ('linear2', nn.Linear(400, 100)),\n",
        "        ('tanh2', nn.Tanh()),\n",
        "        ('linear3', nn.Linear(100, 10)),\n",
        "        ('tanh3', nn.Tanh()),\n",
        "    ])\n",
        "\n",
        "params3 = {'ord_dict': model_params_3, 'device': device}\n",
        "\n",
        "params = {\n",
        "    'model_params': [params1, params2, params3]\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "metrics = model_runner.get_metrics()\n",
        "fc_activations_table = PrettyTable()\n",
        "fc_activations_table.add_column('Активации', ['softplus', 'sigmoid', 'tanh'])\n",
        "fc_activations_table.add_column('Точность', list(map(lambda x: f'{float(x[0].detach().cpu().numpy()):.4f}', metrics)),)\n",
        "print(fc_activations_table)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "LP1JxHUQUd9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Количество эпох"
      ],
      "metadata": {
        "id": "mOAgtpeNA2K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'epochs': [5, 10, 25, 40, 80]\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "metrics = model_runner.get_metrics()\n",
        "fc_epochs_table = PrettyTable()\n",
        "fc_epochs_table.add_column('Эпохи', ['5', '10', '25', '40', '80'])\n",
        "fc_epochs_table.add_column('Точность', list(map(lambda x: f'{float(x[0].detach().cpu().numpy()):.4f}', metrics)),)\n",
        "print(fc_epochs_table)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "nIFnqSv0A5za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сверточная нейронная сеть\n",
        "\n",
        "### Скорость обучения"
      ],
      "metadata": {
        "id": "Mst7FNWRXMbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*7*7, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "\n",
        "optim_params_1 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-2,\n",
        "}\n",
        "optim_params_2 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-3,\n",
        "}\n",
        "\n",
        "optim_params_3 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-4,\n",
        "}\n",
        "\n",
        "optim_params_4 = {\n",
        "    'name': 'Adam',\n",
        "    'params': None,\n",
        "    'lr': 1e-5,\n",
        "}\n",
        "\n",
        "trainer_hp['model_params']['ord_dict'] = model_params\n",
        "\n",
        "\n",
        "params = {\n",
        "    'set_optimizer': [optim_params_1, optim_params_2, optim_params_3, optim_params_4]\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "metrics = model_runner.get_metrics()\n",
        "conv_lr_table = PrettyTable()\n",
        "conv_lr_table.add_column('Скорость обучения', ['1e-2', '1e-3', '1e-4', '1e-5'])\n",
        "conv_lr_table.add_column('Точность', list(map(lambda x: f'{float(x[0].detach().cpu().numpy()):.4f}', metrics)),)\n",
        "print(conv_lr_table)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "-lzIKVMwXVS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Количество слоев"
      ],
      "metadata": {
        "id": "cuRqQuaYXwGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params_1 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(16*14*14, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "    \n",
        "params1 = {'ord_dict': model_params_1, 'device': device}\n",
        "\n",
        "model_params_2 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*7*7, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "params2 = {'ord_dict': model_params_2, 'device': device}\n",
        "    \n",
        "model_params_3 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 32, (2, 2), stride=1, padding=1)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv3', nn.Conv2d(32, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('maxpool3', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*3*3, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "params3 = {'ord_dict': model_params_3, 'device': device}\n",
        "\n",
        "params = {\n",
        "    'model_params': [params1, params2, params3],\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "metrics = model_runner.get_metrics()\n",
        "conv_layers_table = PrettyTable()\n",
        "conv_layers_table.add_column('Количество слоев', ['1', '2', '3'])\n",
        "conv_layers_table.add_column('Точность', list(map(lambda x: f'{float(x[0].detach().cpu().numpy()):.4f}', metrics)),)\n",
        "print(conv_layers_table)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "gxI8vZEOX0bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Количество нейронов"
      ],
      "metadata": {
        "id": "MPpdCLzdZJ5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params_1 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 8, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(8, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(16*7*7, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "params1 = {'ord_dict': model_params_1, 'device': device}\n",
        "\n",
        "model_params_2 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*7*7, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "params2 = {'ord_dict': model_params_2, 'device': device}\n",
        "\n",
        "model_params_3 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(64, 128, (2, 2), stride=1, padding=1)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(128*7*7, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "params3 = {'ord_dict': model_params_3, 'device': device}\n",
        "\n",
        "params = {\n",
        "    'model_params': [params1, params2, params3],\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "metrics = model_runner.get_metrics()\n",
        "conv_neurons_table = PrettyTable()\n",
        "\n",
        "conv_neurons_table.add_column('Количество нейронов', ['8 16', '16 64', '64 128'])\n",
        "conv_neurons_table.add_column('Точность', list(map(lambda x: f'{float(x[0].detach().cpu().numpy()):.4f}', metrics)),)\n",
        "print(conv_neurons_table)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "QbCR1xpkZ7Br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Функции активации\n",
        "Вместо софтплюс возьму LeakyRELU"
      ],
      "metadata": {
        "id": "nwkQu3EKa2VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params_1 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.LeakyReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('relu2', nn.LeakyReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*7*7, 100)),\n",
        "    ('relu3', nn.LeakyReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.LeakyReLU()),\n",
        "    ])\n",
        "params1 = {'ord_dict': model_params_1, 'device': device}\n",
        "\n",
        "model_params_2 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('sigmoid1', nn.Sigmoid()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('sigmoid2', nn.Sigmoid()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*7*7, 100)),\n",
        "    ('sigmoid3', nn.Sigmoid()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('sigmoid4', nn.Sigmoid()),\n",
        "    ])\n",
        "params2 = {'ord_dict': model_params_2, 'device': device}\n",
        "\n",
        "model_params_3 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('tanh1', nn.Tanh()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('tanh2', nn.Tanh()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*7*7, 100)),\n",
        "    ('tanh3', nn.Tanh()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('tanh4', nn.Tanh()),\n",
        "    ])\n",
        "params3 = {'ord_dict': model_params_3, 'device': device}\n",
        "\n",
        "params = {\n",
        "    'model_params': [params1, params2, params3],\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "metrics = model_runner.get_metrics()\n",
        "conv_activations_table = PrettyTable()\n",
        "\n",
        "conv_activations_table.add_column('Активации', ['LeakyReLU', 'sigmoid', 'tanh'])\n",
        "\n",
        "conv_activations_table.add_column('Точность', list(map(lambda x: f'{float(x[0].detach().cpu().numpy()):.4f}', metrics)),)\n",
        "print(conv_activations_table)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "jeBgWGJabIsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Количество эпох"
      ],
      "metadata": {
        "id": "RZDxUsukBi8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'epochs': [5, 10, 25, 40, 80]\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "metrics = model_runner.get_metrics()\n",
        "conv_epochs_table = PrettyTable()\n",
        "\n",
        "conv_epochs_table.add_column('Эпохи', ['5', '10', '25', '40', '80'])\n",
        "\n",
        "conv_epochs_table.add_column('Точность', list(map(lambda x: f'{float(x[0].detach().cpu().numpy()):.4f}', metrics)),)\n",
        "print(conv_epochs_table)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "SSaIYe0mBleA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Изменение фильтра"
      ],
      "metadata": {
        "id": "KgFQ5UlVcmUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        # W_res = (W-F+2P)/S + 1\n",
        "model_params_1 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (1, 1), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (1, 1), stride=1, padding=1)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*8*8, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "params1 = {'ord_dict': model_params_1, 'device': device}\n",
        "\n",
        "        # W_res = (W-F+2P)/S + 1\n",
        "model_params_2 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (3, 3), stride=1, padding=1)),\n",
        "    ('sigmoid1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (3, 3), stride=1, padding=1)),\n",
        "    ('sigmoid2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*7*7, 100)),\n",
        "    ('sigmoid3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('sigmoid4', nn.ReLU()),\n",
        "    ])\n",
        "params2 = {'ord_dict': model_params_2, 'device': device}\n",
        "\n",
        "        # W_res = (W-F+2P)/S + 1\n",
        "model_params_3 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (4, 4), stride=1, padding=1)),\n",
        "    ('tanh1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (4, 4), stride=1, padding=1)),\n",
        "    ('tanh2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*6*6, 100)),\n",
        "    ('tanh3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('tanh4', nn.Relu()),\n",
        "    ])\n",
        "params3 = {'ord_dict': model_params_3, 'device': device}\n",
        "\n",
        "params = {\n",
        "    'model_params': [params1, params2, params3],\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "metrics = model_runner.get_metrics()\n",
        "conv_filter_table = PrettyTable()\n",
        "\n",
        "conv_filter_table.add_column('Размер фильтра', ['1x1', '3x3', '4x4'])\n",
        "\n",
        "conv_filter_table.add_column('Точность', list(map(lambda x: f'{float(x[0].detach().cpu().numpy()):.4f}', metrics)),)\n",
        "print(conv_filter_table)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "ajbdSX3Ycpis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Размер слоя MaxPool2d"
      ],
      "metadata": {
        "id": "qzamG1HK-gcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        # W_res = (W-F+2P)/S + 1\n",
        "model_params_1 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*30*30, 100)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "params1 = {'ord_dict': model_params_1, 'device': device}\n",
        "\n",
        "        # W_res = (W-F+2P)/S + 1\n",
        "model_params_2 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('sigmoid1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((3, 3))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('sigmoid2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((3, 3))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*3*3, 100)),\n",
        "    ('sigmoid3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('sigmoid4', nn.ReLU()),\n",
        "    ])\n",
        "params2 = {'ord_dict': model_params_2, 'device': device}\n",
        "\n",
        "        # W_res = (W-F+2P)/S + 1\n",
        "model_params_3 = OrderedDict([\n",
        "    ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "    ('tanh1', nn.ReLU()),\n",
        "    ('maxpool1', nn.MaxPool2d((4, 4))),\n",
        "\n",
        "    ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "    ('tanh2', nn.ReLU()),\n",
        "    ('maxpool2', nn.MaxPool2d((4, 4))),\n",
        "\n",
        "    ('flatten3', nn.Flatten()),\n",
        "    ('linear3', nn.Linear(64*1*1, 100)),\n",
        "    ('tanh3', nn.ReLU()),\n",
        "    ('linear4', nn.Linear(100, 10)),\n",
        "    ('tanh4', nn.Relu()),\n",
        "    ])\n",
        "params3 = {'ord_dict': model_params_3, 'device': device}\n",
        "\n",
        "params = {\n",
        "    'model_params': [params1, params2, params3],\n",
        "}\n",
        "\n",
        "model_runner = ModelRunner(Trainer, trainer_hp, metrics=trainer_hp['metrics'])\n",
        "model_runner.run(train_dataset, val_dataset, params)\n",
        "metrics = model_runner.get_metrics()\n",
        "conv_maxpool_table = PrettyTable()\n",
        "\n",
        "conv_maxpool_table.add_column('Размер слоя MaxPool', ['1x1', '3x3', '4x4'])\n",
        "\n",
        "conv_maxpool_table.add_column('Точность', list(map(lambda x: f'{float(x[0].detach().cpu().numpy()):.4f}', metrics)),)\n",
        "print(conv_maxpool_table)\n",
        "del model_runner"
      ],
      "metadata": {
        "id": "tqabRQ3N-g_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Вывод"
      ],
      "metadata": {
        "id": "HMl1eNX3_rcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('===== Полносвязная сеть =====')\n",
        "print(fc_lr_table)\n",
        "print(fc_layers_table)\n",
        "print(fc_neurons_table)\n",
        "print(fc_activations_table)\n",
        "print('===== Свёрточная сеть =====')\n",
        "print(conv_lr_table)\n",
        "print(conv_layers_table)\n",
        "print(conv_neurons_table)\n",
        "print(conv_activations_table)\n",
        "print(conv_filter_table)\n",
        "print(conv_maxpool_table)"
      ],
      "metadata": {
        "id": "TsLiIXIx_u2B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "ec8a8ec9-8652-4919-9ffa-047545db3a03"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Полносвязная сеть =====\n",
            "+------------------------+-------------------+\n",
            "|        Точность        | Скорость обучения |\n",
            "+------------------------+-------------------+\n",
            "| 0.7645565271377563:.4f |        1e-2       |\n",
            "| 0.775442361831665:.4f  |        1e-3       |\n",
            "| 0.7748718857765198:.4f |        1e-4       |\n",
            "| 0.7751721143722534:.4f |        1e-5       |\n",
            "+------------------------+-------------------+\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m===== Полносвязная сеть =====\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(fc_lr_table)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfc_layers_table\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(fc_neurons_table)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(fc_activations_table)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fc_layers_table' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данном случае, в среднем, полносвязная сеть показывает большую точность, чем сверточная. Возможно это связано с отсутствием нормализации входного тензора и неправильной структуры сверточной сети.\n",
        "\n",
        "В результате тестирования полносвязной сети, можно заметить что существует определенное оптимальное значение гиперпараметра, при отклонении от которого точность снижается. Это видно в таблице Скорость обучения, Количество слоев, Количество нейронов, Количество эпох. Наилучшая функция активации - Relu, наихудшая - сигмоида.\n",
        "\n",
        "В сверточных сетях видны следующие закономерности: \n",
        "- точность выше при большой скорости обучения\n",
        "- одного сверточного слоя не хватает для адекватной классификации\n",
        "- наилучшая функция активации - Relu, при активании - сигмоиде модель не работает\n",
        "- по точности в зависимости от количества эпох можно предположить, что модель быстро обучается но при этом не склонна к переобучению\n",
        "- большой размер фильтра уменьшает количество нейронов в финальном полносвязном слое, похоже что это увеличивает точность"
      ],
      "metadata": {
        "id": "oHuDwDshAomf"
      }
    }
  ]
}