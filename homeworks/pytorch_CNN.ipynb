{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrRcfqRH1J7/SU/nW4an6f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvarkless/InnopolisDS/blob/main/homeworks/pytorch_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG9EDrfD5pmg",
        "outputId": "402365c1-4b4c-4656-e370-8aa74a563c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========Epoch 1/20==========\n",
            "Loss: 1.2967389822006226\n",
            "Accuracy = 0.884\n",
            "Recall = 0.884\n",
            "Precision = 0.888\n",
            "==========Epoch 2/20==========\n",
            "Loss: 0.4429587721824646\n",
            "Accuracy = 0.923\n",
            "Recall = 0.923\n",
            "Precision = 0.923\n",
            "==========Epoch 3/20==========\n",
            "Loss: 0.2905564308166504\n",
            "Accuracy = 0.940\n",
            "Recall = 0.940\n",
            "Precision = 0.940\n",
            "==========Epoch 4/20==========\n",
            "Loss: 0.2298288494348526\n",
            "Accuracy = 0.950\n",
            "Recall = 0.950\n",
            "Precision = 0.950\n",
            "==========Epoch 5/20==========\n",
            "Loss: 0.19461113214492798\n",
            "Accuracy = 0.954\n",
            "Recall = 0.954\n",
            "Precision = 0.954\n",
            "==========Epoch 6/20==========\n",
            "Loss: 0.1706569343805313\n",
            "Accuracy = 0.959\n",
            "Recall = 0.959\n",
            "Precision = 0.959\n",
            "==========Epoch 7/20==========\n",
            "Loss: 0.15299151837825775\n",
            "Accuracy = 0.964\n",
            "Recall = 0.964\n",
            "Precision = 0.964\n",
            "==========Epoch 8/20==========\n",
            "Loss: 0.1392328441143036\n",
            "Accuracy = 0.966\n",
            "Recall = 0.966\n",
            "Precision = 0.966\n",
            "==========Epoch 9/20==========\n",
            "Loss: 0.12814292311668396\n",
            "Accuracy = 0.969\n",
            "Recall = 0.969\n",
            "Precision = 0.969\n",
            "==========Epoch 10/20==========\n",
            "Loss: 0.11899322271347046\n",
            "Accuracy = 0.971\n",
            "Recall = 0.971\n",
            "Precision = 0.971\n",
            "==========Epoch 11/20==========\n",
            "Loss: 0.11129086464643478\n",
            "Accuracy = 0.973\n",
            "Recall = 0.973\n",
            "Precision = 0.973\n",
            "==========Epoch 12/20==========\n",
            "Loss: 0.1046813577413559\n",
            "Accuracy = 0.974\n",
            "Recall = 0.974\n",
            "Precision = 0.974\n",
            "==========Epoch 13/20==========\n",
            "Loss: 0.09894908964633942\n",
            "Accuracy = 0.975\n",
            "Recall = 0.975\n",
            "Precision = 0.976\n",
            "==========Epoch 14/20==========\n",
            "Loss: 0.09392621368169785\n",
            "Accuracy = 0.977\n",
            "Recall = 0.977\n",
            "Precision = 0.977\n",
            "==========Epoch 15/20==========\n",
            "Loss: 0.08947279304265976\n",
            "Accuracy = 0.978\n",
            "Recall = 0.978\n",
            "Precision = 0.978\n",
            "==========Epoch 16/20==========\n",
            "Loss: 0.08549918234348297\n",
            "Accuracy = 0.978\n",
            "Recall = 0.978\n",
            "Precision = 0.978\n",
            "==========Epoch 17/20==========\n",
            "Loss: 0.08192229270935059\n",
            "Accuracy = 0.979\n",
            "Recall = 0.979\n",
            "Precision = 0.979\n",
            "==========Epoch 18/20==========\n",
            "Loss: 0.07867740839719772\n",
            "Accuracy = 0.979\n",
            "Recall = 0.979\n",
            "Precision = 0.979\n",
            "==========Epoch 19/20==========\n",
            "Loss: 0.07570744305849075\n",
            "Accuracy = 0.980\n",
            "Recall = 0.980\n",
            "Precision = 0.980\n",
            "==========Epoch 20/20==========\n",
            "Loss: 0.07299292832612991\n",
            "Accuracy = 0.980\n",
            "Recall = 0.980\n",
            "Precision = 0.980\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from collections import OrderedDict\n",
        "from typing import OrderedDict as OrderedDictType\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchmetrics import Accuracy, Precision, Recall\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose, Normalize, ToTensor\n",
        "\n",
        "\n",
        "class SeqModeler(nn.Sequential):\n",
        "    def __init__(self, ord_dict: OrderedDictType, device='cpu') -> None:\n",
        "        super().__init__(ord_dict)\n",
        "        self.device = torch.device(device)\n",
        "        self.to(self.device, non_blocking=True)\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = self.forward(X)\n",
        "        return torch.argmax(nn.Softmax(dim=1)(X), dim=1)\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    __defaults = {\n",
        "        'batch_size': 100,\n",
        "        'device': 'cpu',\n",
        "        'epochs': 20,\n",
        "        'criterion': nn.CrossEntropyLoss(),\n",
        "        'enable_print': False,\n",
        "        'metrics': None,\n",
        "    }\n",
        "    __must_have_params = ['model_class', 'model_params', 'set_optimizer']\n",
        "\n",
        "    def __init__(self, **hp) -> None:\n",
        "        self.config = self.__defaults.copy()\n",
        "        for name, val in hp.items():\n",
        "            self.config[name] = val\n",
        "\n",
        "        for name in self.__must_have_params:\n",
        "            if name not in self.config:\n",
        "                print(f'Error: config parameter \"{name}\" is missing')\n",
        "                sys.exit(1)\n",
        "\n",
        "        self.model = self.config['model_class'](**self.config['model_params'])\n",
        "        opt_config = self.config['set_optimizer'].copy()\n",
        "        opt_config['params'] = self.model.parameters()\n",
        "        optimizer_name = opt_config.pop('name')\n",
        "        self.optimizer = getattr(torch.optim, optimizer_name)(**opt_config)\n",
        "        self.criterion = self.config['criterion']\n",
        "        self.device = torch.device(self.config['device'])\n",
        "\n",
        "    @property\n",
        "    def data_batch(self):\n",
        "        return self._data_batch\n",
        "\n",
        "    @data_batch.setter\n",
        "    def data_batch(self, data, /):\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            self._data_batch = data.to(self.device, non_blocking=True).float()\n",
        "        elif isinstance(data, np.ndarray):\n",
        "            self.data_batch = torch.Tensor(data)\n",
        "        else:\n",
        "            raise ValueError(f'data of type {type(data)} is unacceptable')\n",
        "\n",
        "    @property\n",
        "    def targets_batch(self):\n",
        "        return self._targets_batch\n",
        "\n",
        "    @targets_batch.setter\n",
        "    def targets_batch(self, targets):\n",
        "        if isinstance(targets, torch.Tensor):\n",
        "            self._targets_batch = targets.to(\n",
        "                self.device, non_blocking=True)\n",
        "        elif isinstance(targets, (np.ndarray, list, tuple)):\n",
        "            self.targets_batch = torch.Tensor(targets)\n",
        "        else:\n",
        "            raise ValueError(f'data of type {type(targets)} is unacceptable')\n",
        "\n",
        "    def fit(self, train_dataset, eval_dataset=None):\n",
        "        train_dl = DataLoader(train_dataset, self.config['batch_size'])\n",
        "        for epoch in range(self.config['epochs']):\n",
        "            avg_loss = []\n",
        "            for (inputs, targets) in train_dl:\n",
        "                self.data_batch, self.targets_batch = inputs, targets\n",
        "                self.optimizer.zero_grad()\n",
        "                yhat = self.model(self.data_batch)\n",
        "                loss = self.criterion(yhat, self.targets_batch)\n",
        "                avg_loss.append(loss)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "            avg_loss = torch.Tensor(avg_loss).mean()\n",
        "            avg_loss.to(self.device)\n",
        "            if self.config['enable_print']:\n",
        "                print(\n",
        "                    f'==========Epoch {epoch+1}/{self.config[\"epochs\"]}==========')\n",
        "                print(f'Loss: {avg_loss}')\n",
        "                if self.config['metrics'] and eval_dataset:\n",
        "                    metric_data = self.evaluate(eval_dataset)\n",
        "                    for metric, data in zip(self.config['metrics'], metric_data):\n",
        "                        print(f'{metric.__class__.__name__} = {data:.3f}')\n",
        "        return self\n",
        "\n",
        "    def evaluate(self, eval_dataset):\n",
        "        eval_dl = DataLoader(eval_dataset, batch_size=10000)\n",
        "        for data, targets in eval_dl:\n",
        "            self.data_batch, self.targets_batch = data, targets\n",
        "            predictions = self.model.predict(self.data_batch)\n",
        "            metric_data = []\n",
        "            for metric in self.config['metrics']:\n",
        "                metric_data.append(metric(predictions, self.targets_batch))\n",
        "            return tuple(metric_data)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\n",
        "        'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    trans = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
        "    train = MNIST('data/', train=True, download=True, transform=trans)\n",
        "    test = MNIST('data/', train=False, download=True, transform=trans)\n",
        "    model_params = OrderedDict([\n",
        "        ('batch1', nn.BatchNorm2d(1)),\n",
        "        ('conv1', nn.Conv2d(1, 16, (2, 2), stride=1, padding=1)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('maxpool1', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "        ('batch2', nn.BatchNorm2d(16)),\n",
        "        ('conv2', nn.Conv2d(16, 64, (2, 2), stride=1, padding=1)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "        ('maxpool2', nn.MaxPool2d((2, 2))),\n",
        "\n",
        "        ('flatten3', nn.Flatten()),\n",
        "        ('batch3', nn.BatchNorm1d(64*7*7)),\n",
        "        ('linear3', nn.Linear(64*7*7, 100)),\n",
        "        ('relu3', nn.ReLU()),\n",
        "        ('linear4', nn.Linear(100, 10)),\n",
        "        ('relu4', nn.ReLU()),\n",
        "    ])\n",
        "    optim_params = {\n",
        "        'name': 'SGD',\n",
        "        'params': None,\n",
        "        'lr': 1e-4,\n",
        "        'momentum': 0.9,\n",
        "    }\n",
        "    trainer_hp = {\n",
        "        'batch_size': 50,\n",
        "        'model_class': SeqModeler,\n",
        "        'model_params': {'ord_dict': model_params, 'device': device},\n",
        "        'set_optimizer': optim_params,\n",
        "        'device': device,\n",
        "        'criterion': nn.CrossEntropyLoss(),\n",
        "        'enable_print': True,\n",
        "        'metrics': [Accuracy(num_classes=10, average='macro').to(device), Recall(num_classes=10, average='macro').to(device), Precision(num_classes=10, average='macro').to(device)]\n",
        "    }\n",
        "\n",
        "    trainer = Trainer(**trainer_hp).fit(train, test)"
      ]
    }
  ]
}