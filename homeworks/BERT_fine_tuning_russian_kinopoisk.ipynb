{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvarkless/InnopolisDS/blob/main/homeworks/BERT_fine_tuning_russian_kinopoisk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "8a4PVnfQze",
        "id": "D2lbAqrHi8u7"
      },
      "source": [
        "Sentiment analysis on Kinopoisk movie reviews dataset using pretrained BERT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "jdJD0kgdwf",
        "id": "FBUwkPtvi8u-"
      },
      "source": [
        "Импорты: pytorch, bert, вспомогательные библиотеки ,шкала прогресса, отключение предупреждений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "6gUAGkjX5g",
        "id": "hpQbqjHki8u_"
      },
      "source": [
        "import shutup; shutup.please()\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# BERT imports\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from alive_progress import alive_bar\n",
        "\n",
        "\n",
        "# specify GPU device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    torch.cuda.get_device_name(0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "XIK5TgHpDq",
        "id": "ZwX2TZpni8vB"
      },
      "source": [
        "DATA_DIR=\"../LSTM Sentiment/\"\n",
        "PROP = 0.2"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "ttNy7LFHr3",
        "id": "AqGr9zv4i8vB"
      },
      "source": [
        "Класс кастомного датасета позволит токенизировать текст по мере необходимости"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "oOWb6j5g3N",
        "id": "WIZnnXLNi8vB"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, texts, targets, tokenizer, max_len=512):\n",
        "    self.texts = texts\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if isinstance(idx, int):\n",
        "        idx = idx if idx < len(self) else len(self)-1\n",
        "    text = str(self.texts[idx])\n",
        "    target = self.targets[idx]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=self.max_len,\n",
        "        return_token_type_ids=False,\n",
        "        padding='max_length',\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'text': text,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "wGqITVoinv",
        "id": "NdS0XelYi8vC"
      },
      "source": [
        "dataset_path = DATA_DIR / Path('dataset')\n",
        "\n",
        "df = pd.DataFrame(columns=['review', 'sentiment'])\n",
        "\n",
        "class_names = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "class_names_converter = {\n",
        "    'neg': 'Negative',\n",
        "    'pos': 'Positive',\n",
        "    'neu': 'Neutral',\n",
        "}\n",
        "\n",
        "def standardize_text(df, content_field):\n",
        "    df[content_field] = df[content_field].str.replace(r\"http\\S+\", \"\")\n",
        "    df[content_field] = df[content_field].str.replace(r\"@\\S+\", \"\")\n",
        "    df[content_field] = df[content_field].str.replace(\n",
        "        r\"[^А-Яа-яA-Za-z0-9Ёё(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
        "    df[content_field] = df[content_field].str.replace(r\"[Ёё]\", \"е\")\n",
        "    df[content_field] = df[content_field].str.replace(r\"[\\t\\n]\", \"\")\n",
        "    df[content_field] = df[content_field].str.replace(r\"[^А-Яа-яa-zA-Z]\", \" \")\n",
        "    df[content_field] = df[content_field].str.lower()\n",
        "    return df\n",
        "\n",
        "def name_to_id(name):\n",
        "    return class_names.index(name)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "yyU0dc4G2y",
        "id": "mzeNQMXKi8vD"
      },
      "source": [
        "Загрузим датасет отзывов с кинопоиска в датафрейм Пандас\n",
        "Для этого надо пройтись по каждой директории, открыть текстовый файл и загрузить его содержимое в датафрейм\n",
        "Далее идет стандартизация текста и разбиение его на тестовую и проверочную выборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "miTk5oP3Qe",
        "id": "ioTQ6aHwi8vE",
        "outputId": "7a870ae0-340d-429a-c3ed-f79cf36c4492"
      },
      "source": [
        "for class_path in dataset_path.iterdir():\n",
        "    if class_path.is_dir():\n",
        "        dirs = np.array(list(class_path.iterdir()))\n",
        "        np.random.shuffle(dirs)\n",
        "        rews_fhs = np.random.choice(dirs, round(len(dirs)))\n",
        "        print(f'len = {rews_fhs.shape}')\n",
        "        print(class_names_converter[class_path.name])\n",
        "        for rew_fh in rews_fhs:\n",
        "            with open(Path(rew_fh), encoding='utf-8') as f:\n",
        "                review = f.read()\n",
        "                current_df = pd.DataFrame(\n",
        "                    {'review': [review], 'sentiment': class_names_converter[class_path.name]})\n",
        "                df = pd.concat([df, current_df], ignore_index=True)\n",
        "\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "len = (24704,)\nNeutral\nlen = (87138,)\nPositive\nlen = (19827,)\nNegative\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "                                                   review sentiment\n0       мне не совсем понятно  почему фильм имеет тако...  Positive\n1       после распада советского союза родителям и мне...  Positive\n2       может быть  кто то скажет  что это триллер или...  Positive\n3       великолепный фильм  после просмотра остается м...  Positive\n4       чат   средство обмена сообщениями по компьютер...  Positive\n...                                                   ...       ...\n131664  гилберт грейп живет в маленьком американском г...  Positive\n131665  ах  какие слова  едва ли не любимейший мой мом...  Positive\n131666  в последнее время почему то захотелось лучше п...  Positive\n131667  фильм бесподобен  скажу сразу  если вы скучает...  Positive\n131668   трасса     это фильм о том  к чему могут прив...  Positive\n\n[131669 rows x 2 columns]"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "VgJmtOb6eO",
        "id": "In-H-bnyi8vF"
      },
      "source": [
        "df = standardize_text(df, \"review\")\n",
        "df['sentiment'] = df['sentiment'].map(name_to_id)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "UJgkx05qey",
        "id": "8GVXz5Zsi8vF"
      },
      "source": [
        "train_dataset, eval_dataset = train_test_split(df, test_size=PROP)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "m4LuU1SVJi",
        "id": "dBCEsxKLi8vG"
      },
      "source": [
        "train_dataset.to_csv('Kinopoisk_train.csv')\n",
        "eval_dataset.to_csv('Kinopoisk_eval.csv')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "dGsaWqQbqW",
        "id": "XTQEjpJxi8vG"
      },
      "source": [
        "Так как датасет был конвертирован в csv заранее, то пропустим выполнение строк выше и просто загрузим выборки из файла, который находится в локальной машине"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "hu9qwmWZTB",
        "id": "Mnlsc22qi8vG"
      },
      "source": [
        "train_dataset = pd.read_csv('Kinopoisk_train.csv')\n",
        "eval_dataset = pd.read_csv('Kinopoisk_eval.csv')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "A30BrDHHyO",
        "id": "3wrGJs8xi8vH"
      },
      "source": [
        "Инициируем токенайзер, модель и оборачиваем датасет в кастомный класс\n",
        "Используем модель rubert-tiny2, тк она лучше всего подходит для задач NLP на русском языке"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "FgZV68751q",
        "id": "_ykOqltoi8vH"
      },
      "source": [
        "rubert_path = 'cointegrated/rubert-tiny2'\n",
        "tokenizer = BertTokenizer.from_pretrained(rubert_path)\n",
        " "
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "gNRs7TYZsc",
        "id": "wyidSxhxi8vH"
      },
      "source": [
        "train_dataset = CustomDataset(train_dataset['review'], train_dataset['sentiment'], tokenizer, max_len=512)\n",
        "eval_dataset = CustomDataset(eval_dataset['review'], eval_dataset['sentiment'], tokenizer, max_len=512)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "SJLlzNhzAS",
        "id": "y3yt35Xni8vI"
      },
      "source": [
        "n_classes = 3\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(rubert_path)\n",
        "\n",
        "out_features = model.bert.encoder.layer[1].output.dense.out_features\n",
        "model.classifier = torch.nn.Linear(out_features, n_classes)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "tzpA0ZiE59",
        "id": "2JqM2LgGi8vI"
      },
      "source": [
        "После определения модели можно определить оптимизатор, функцию потерь\n",
        "и класс, который будет обучать и проверять модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "sd1WcvbKLu",
        "id": "gQhU6JZBi8vI"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "94WXLihbFt",
        "id": "vKsgiimwi8vI"
      },
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "6Nndlb083q",
        "id": "_2ERgHcMi8vJ"
      },
      "source": [
        "class BertClassifier:\n",
        "    def __init__(self, model, tokenizer, optimizer, loss, n_classes=3, max_len=512, model_save_path='rubert_on_kinopoisk.pt', log=True):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.optimizer = optimizer\n",
        "        self.loss = loss\n",
        "        self.loss.to(self.device)\n",
        "        self.model_save_path=model_save_path\n",
        "        self.max_len = max_len\n",
        "        self.log = log\n",
        "        self.model.to(self.device)\n",
        "    \n",
        "    def fit(self, train, eval, epochs=2, save_model=True):\n",
        "        self.model = self.model.train()\n",
        "        losses = []\n",
        "        correct_predictions = 0\n",
        "        best_accuracy = 0\n",
        "\n",
        "\n",
        "        train_dl = DataLoader(train, batch_size=16, shuffle=True)\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "                self.optimizer,\n",
        "                num_warmup_steps=0,\n",
        "                num_training_steps=len(train_dl) * epochs\n",
        "            )\n",
        "\n",
        "        with alive_bar(epochs*len(train)//16, title=f'Обучение модели ruBERT', force_tty=True, bar='filling') as bar:\n",
        "            for epoch in range(epochs):\n",
        "\n",
        "                correct_predictions = 0\n",
        "                for data in train_dl:\n",
        "\n",
        "                    input_ids = data[\"input_ids\"].to(self.device)\n",
        "                    attention_mask = data[\"attention_mask\"].to(self.device)\n",
        "                    targets = data[\"targets\"].to(self.device)\n",
        "\n",
        "                    outputs = self.model(\n",
        "                        input_ids=input_ids,\n",
        "                        attention_mask=attention_mask\n",
        "                        )\n",
        "\n",
        "                    preds = torch.argmax(outputs.logits, dim=1)\n",
        "                    loss = self.loss(outputs.logits, targets)\n",
        "\n",
        "                    correct_predictions += torch.sum(preds == targets)\n",
        "\n",
        "                    losses.append(loss.item())\n",
        "                    \n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "                    self.optimizer.step()\n",
        "                    scheduler.step()\n",
        "                    self.optimizer.zero_grad()\n",
        "                    bar()\n",
        "\n",
        "                train_acc = correct_predictions.double() / len(train)\n",
        "                train_loss = np.mean(losses)\n",
        "\n",
        "                eval_acc, eval_loss = self.eval(eval)\n",
        "                \n",
        "                if self.log:\n",
        "                    print(f'===========Epoch {epoch+1}/{epochs}===========')\n",
        "                    print(f'Train loss: {train_loss:.4f} accuracy: {train_acc:.4f}')\n",
        "\n",
        "                    print(f'Val loss {eval_loss:.4f} accuracy {eval_acc:.4f}')\n",
        "\n",
        "                if save_model:\n",
        "                    if eval_acc > best_accuracy:\n",
        "                        torch.save(self.model, self.model_save_path)\n",
        "                        best_accuracy = eval_acc\n",
        "\n",
        "        return self \n",
        "\n",
        "    def eval(self, eval):\n",
        "        self.model = self.model.eval()\n",
        "        losses = []\n",
        "        correct_predictions = 0\n",
        "\n",
        "        eval_dl = DataLoader(eval, batch_size=32, shuffle=True)\n",
        "        with torch.no_grad():\n",
        "            for data in eval_dl:\n",
        "                input_ids = data[\"input_ids\"].to(self.device)\n",
        "                attention_mask = data[\"attention_mask\"].to(self.device)\n",
        "                targets = data[\"targets\"].to(self.device)\n",
        "\n",
        "                outputs = self.model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask\n",
        "                    )\n",
        "\n",
        "                preds = torch.argmax(outputs.logits, dim=1)\n",
        "                loss = self.loss(outputs.logits, targets)\n",
        "                correct_predictions += torch.sum(preds == targets)\n",
        "                losses.append(loss.item())\n",
        "        \n",
        "        val_acc = correct_predictions.double() / len(eval)\n",
        "        val_loss = np.mean(losses)\n",
        "        return val_acc, val_loss\n",
        "    \n",
        "    def predict(self, text):\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "        \n",
        "        out = {\n",
        "              'text': text,\n",
        "              'input_ids': encoding['input_ids'].flatten(),\n",
        "              'attention_mask': encoding['attention_mask'].flatten()\n",
        "          }\n",
        "        \n",
        "        input_ids = out[\"input_ids\"].to(self.device)\n",
        "        attention_mask = out[\"attention_mask\"].to(self.device)\n",
        "        \n",
        "        outputs = self.model(\n",
        "            input_ids=input_ids.unsqueeze(0),\n",
        "            attention_mask=attention_mask.unsqueeze(0)\n",
        "        )\n",
        "        \n",
        "        prediction = torch.argmax(outputs.logits, dim=1).cpu().numpy()[0]\n",
        "\n",
        "        return prediction"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "rYT7ZKqJ9g",
        "id": "SLKplFoOi8vJ"
      },
      "source": [
        "обучение модели, сохранение обученной модели в файле"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "cpSBILUvCR",
        "id": "7rn16C5Hi8vJ",
        "outputId": "3dc25e1b-3c0f-4367-b63b-0e53f8a4e302"
      },
      "source": [
        "model_runner = BertClassifier(model, tokenizer, optimizer, loss_fn).fit(train_dataset, eval_dataset, epochs=5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "on 6584: ===========Epoch 1/5===========\non 6584: Train loss: 0.4783 accuracy: 0.8084\non 6584: Val loss 0.4789 accuracy 0.8125\non 13168: ===========Epoch 2/5===========\non 13168: Train loss: 0.4051 accuracy: 0.8798\non 13168: Val loss 0.4492 accuracy 0.8470\non 19752: ===========Epoch 3/5===========\non 19752: Train loss: 0.3363 accuracy: 0.9390\non 19752: Val loss 0.5303 accuracy 0.8650\non 26336: ===========Epoch 4/5===========\non 26336: Train loss: 0.2810 accuracy: 0.9715\non 26336: Val loss 0.7322 accuracy 0.8718\non 32920: ===========Epoch 5/5===========\non 32920: Train loss: 0.2378 accuracy: 0.9864\non 32920: Val loss 0.7933 accuracy 0.8721\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "vNovJXkUnM",
        "id": "L3cWcP-Pi8vK"
      },
      "source": [
        "Проверка модели.\n",
        "Данные взяты из Кинопоиска, отзывы на недавно вышедшие фильмы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "PmkGsh5ccF",
        "id": "Xrqr7lOji8vK",
        "outputId": "4ae84873-9077-4727-b075-b217430109b9"
      },
      "source": [
        "# Отрицательный отзыв на фильм Морбиус (2022) \n",
        "header = \"Morbius 2022\"\n",
        "review = \"Ну, я даже не знаю, какой супергеройский фильм последних лет может хотя бы на толику быть на столько ужасным. Абсолютно не спасает этот плевок в сторону фан-сообщества наличие нестареющего (видимо действительно вампирского происхождения) Джареда Лето. Хотя, чего уж скрывать, он всё равно красавчик, и эта роль ему на все сто процентов подходит, НО только при наличии адекватного сценария и не отвлекающегося на перекуры и другие интересные дела режиссера\"\n",
        "correct = \"Negative\"\n",
        "model_out = model_runner.predict(review)\n",
        "print(f'Результат модели: This review about \"{header}\" is {class_names[model_out]} (in fact it is {correct})')\n",
        "\n",
        "# Положительный Avengers: Endgame, 2019\n",
        "header = \"Avengers: Endgame, 2019\"\n",
        "review = \"Есть фильмы, которые хороши не потому, что в них все идеально. Картина может иметь сотню недостатков, куча дыр и несостыковок, завышенные ожидания со стороны зрителей, но все равно цепляет и оставляет по себе очень приятное послевкусие. Именно к таким фильмам лично я для себя причисляю Мстителей. Финал'. Просматривая его третий раз в кино, я поняла, что еще раз и смогу разложить и сюжет и мотивацию героев по атомам, тем не менее, ни ненависти ни какого-то огорчения я не испытываю. Если бы меня спросили, что бы я поменяла, то определенно получилось бы эссе на несколько страничек мелкого почерка. С другой стороны, мы получили весьма зрелищное и душевное окончание многолетней саги, увидели любимых персонажей, вдоволь посмеялись и даже местами поплакали. А раз фильм был способен вызвать такую гамму эмоций, значит создатели сделали почти все правильно.\"\n",
        "correct = \"Positive\"\n",
        "model_out = model_runner.predict(review)\n",
        "print(f'Результат модели: This review about \"{header}\" is {class_names[model_out]} (in fact it is {correct})')\n",
        "\n",
        "# Отрицательный Justice League, 2017\n",
        "header = \"Justice League, 2017\"\n",
        "review = \"И тут все дело в подаче. Понятно что в комиксах вселенная DC давно существует и там Бэтмен и Лига Справедливости спина к спине оберегают Землю. Но в кино мире - Бэтмен всегда был одиночкой, и соперники у него были под стать - без исключительных суперспособностей. И теперь DC пытается впихнуть героя, который в массовом сознании прослыл 'одиноким рейнджером' к героям у которых настоящие суперсилы и суперспособности. Бэтмен на их фоне выглядит ну совсем никак. Но даже не смотря на диссонанс с Бэтменом у DC большие проблемы: 'Лига справедливости', по сравнению с 'Мстителями' выглядит просто дешевой поделкой, вроде все как у них но нет того ощущения постоянного драйва, герои раскрыты однобоко, а вечный пафос раздражает - так как ощущается чем то инородным и неуместным к данной картине. Сюжет в Лиге очень плоский, спецэффекты на уровне, но если их не сдабривать нужным эмоциональным фоном, они начинают смотреться как нарезка трюков. Конечно были в фильмы проблески чего то хорошего, но на общем фоне картины они не осели в памяти, зато осело разочарование от завышенных ожиданий\"\n",
        "correct = \"Negative\"\n",
        "model_out = model_runner.predict(review)\n",
        "print(f'Результат модели: This review about \"{header}\" is {class_names[model_out]} (in fact it is {correct})')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Результат модели: This review about \"Morbius 2022\" is Neutral (in fact it is Negative)\nРезультат модели: This review about \"Avengers: Endgame, 2019\" is Positive (in fact it is Positive)\nРезультат модели: This review about \"Justice League, 2017\" is Negative (in fact it is Negative)\n"
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}